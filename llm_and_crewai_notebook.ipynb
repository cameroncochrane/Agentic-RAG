{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3316f88a",
   "metadata": {},
   "source": [
    "<h2>Agentic RAG App: Groq LLM</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e56ab",
   "metadata": {},
   "source": [
    "<h3>LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c845f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cameroncochrane/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# LangChain has a Groq chat model integration:\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a03ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API groq API key:\n",
    "from pathlib import Path\n",
    "# Bespoke API key loader functions:\n",
    "from load_keys import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc9c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"keys/groq.json\")\n",
    "groq_api_key = load_groq_key(p)\n",
    "os.environ['GROQ_API_KEY'] = groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9814ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model:\n",
    "model = ChatGroq(\n",
    "            model=\"openai/gpt-oss-120b\",\n",
    "            temperature=0.2,\n",
    "            max_retries=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22262716",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = [(\"human\",\"hello, how are you?\")]\n",
    "answer_1 = model.invoke(initial_message) # .invoke to send a message to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a66c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing great, thank you for asking. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "extracted_message = answer_1.content # x.content returns the message for the user.\n",
    "print(extracted_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c939dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I donâ€™t have the ability to browse the web or access realâ€‘time internet data. My responses are based on the information I was trained on, which goes up to Septemberâ€¯2021 (with some updates through 2024). If you need the most current information, youâ€™ll need to check a reliable source directly.\n"
     ]
    }
   ],
   "source": [
    "internet_message = [(\"human\",\"Do you have internet access?\")]\n",
    "internet_answer = model.invoke(internet_message)\n",
    "print(internet_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945c233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm(model_type:str = 'openai/gpt-oss-120b',api_key_path:str = \"keys/groq.json\"):\n",
    "    \n",
    "    p = Path(api_key_path)\n",
    "\n",
    "    groq_api_key = load_groq_key(p)\n",
    "    os.environ['GROQ_API_KEY'] = groq_api_key\n",
    "    \n",
    "    model = ChatGroq(\n",
    "            model=model_type,\n",
    "            temperature=0.2,\n",
    "            max_retries=2,\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c705dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_message(model,message):\n",
    "\n",
    "    full_answer = model.invoke(message)\n",
    "    extracted_answer = full_answer.content\n",
    "\n",
    "    return extracted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e383e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m a versatile, textâ€‘based AI, so I can help with a wide range of tasks across many domains. Here are some of the most common use cases people find valuable:\n",
      "\n",
      "| Category | Typical Tasks | How I Help |\n",
      "|----------|----------------|------------|\n",
      "| **Writing & Editing** | â€¢ Drafting emails, reports, essays, blog posts, socialâ€‘media captions<br>â€¢ Proofreading for grammar, style, tone, and clarity<br>â€¢ Reâ€‘phrasing, summarizing, or expanding text | I generate first drafts, suggest improvements, and polish language to match the desired audience or brand voice. |\n",
      "| **Creative Work** | â€¢ Brainstorming story ideas, plot twists, characters, worldâ€‘building<br>â€¢ Writing poetry, song lyrics, jokes, or marketing copy<br>â€¢ Generating prompts for visual art or DALLâ€‘E | I provide fresh concepts, iterate on feedback, and help you overcome writerâ€™s block. |\n",
      "| **Learning & Tutoring** | â€¢ Explaining concepts in math, science, history, programming, etc.<br>â€¢ Walking through problemâ€‘solving steps or proofs<br>â€¢ Creating practice questions, flashcards, or study guides | I break down complex topics into biteâ€‘size explanations, adapt to your current knowledge level, and give examples. |\n",
      "| **Programming & Technical Help** | â€¢ Writing, debugging, or refactoring code in many languages (Python, JavaScript, Java, C++, etc.)<br>â€¢ Explaining algorithms, data structures, or design patterns<br>â€¢ Generating documentation, API specs, or unit tests | I can produce code snippets, review existing code, suggest improvements, and explain why something works (or doesnâ€™t). |\n",
      "| **Research & Information Retrieval** | â€¢ Summarizing articles, papers, or long documents<br>â€¢ Compiling lists of resources, tools, or best practices<br>â€¢ Factâ€‘checking (within the limits of my knowledge cutoff) | I synthesize information into concise overviews and point out where you might need to verify details. |\n",
      "| **Productivity & Organization** | â€¢ Creating toâ€‘do lists, project plans, meeting agendas, or timelines<br>â€¢ Drafting SOPs, checklists, or workflow diagrams (textual description)<br>â€¢ Generating email templates, autoâ€‘responses, or followâ€‘up scripts | I help you structure tasks, set priorities, and keep communication clear and consistent. |\n",
      "| **Language & Communication** | â€¢ Translating text between many languages (with varying fluency)<br>â€¢ Explaining idioms, cultural references, or tone differences<br>â€¢ Practicing conversation in a target language | I provide translations, languageâ€‘learning tips, and roleâ€‘play scenarios. |\n",
      "| **Data & Analytics (nonâ€‘confidential)** | â€¢ Explaining statistical concepts, visualizing data ideas, or suggesting analysis approaches<br>â€¢ Writing SQL queries, pandas scripts, or R code for data manipulation<br>â€¢ Interpreting sample results and suggesting next steps | I guide you through the analytical workflow and help you write reproducible code. |\n",
      "| **Customer Support & FAQ Generation** | â€¢ Drafting responses to common customer inquiries<br>â€¢ Building knowledgeâ€‘base articles or troubleshooting guides<br>â€¢ Simulating chatbot dialogues for testing | I produce clear, empathetic replies and help you organize information for selfâ€‘service portals. |\n",
      "| **Personal Assistance** | â€¢ Planning trips, itineraries, or packing lists<br>â€¢ Recommending books, movies, recipes, or fitness routines<br>â€¢ Offering motivational prompts or habitâ€‘tracking ideas | I tailor suggestions to your preferences and constraints. |\n",
      "\n",
      "---\n",
      "\n",
      "### How to Get the Most Out of Me\n",
      "\n",
      "1. **Be Specific** â€“ The clearer your prompt (e.g., â€œWrite a 150â€‘word LinkedIn post about remote work trends, targeting tech managersâ€), the more targeted the output.\n",
      "2. **Iterate** â€“ Feel free to ask followâ€‘up questions, request revisions, or ask for alternative styles.\n",
      "3. **Provide Context** â€“ If you have existing text, data, or constraints, share them; I can adapt my response accordingly.\n",
      "4. **Set the Tone** â€“ Mention the desired voice (formal, friendly, persuasive, technical, etc.) up front.\n",
      "5. **Ask for Structure** â€“ If you need bullet points, tables, stepâ€‘byâ€‘step guides, or code comments, just specify.\n",
      "\n",
      "---\n",
      "\n",
      "### Example Prompts\n",
      "\n",
      "- *â€œSummarize the key findings of this 5â€‘page research abstract in three bullet points.â€*\n",
      "- *â€œWrite a Python function that reads a CSV file and returns the top 5 rows with the highest values in column â€˜salesâ€™.â€*\n",
      "- *â€œHelp me draft a polite email to request a deadline extension from my professor.â€*\n",
      "- *â€œGive me a 7â€‘day meal plan for a vegetarian who wants 1800â€¯kcal per day.â€*\n",
      "- *â€œExplain the concept of â€˜gradient descentâ€™ as if Iâ€™m a highâ€‘school student.â€*\n",
      "\n",
      "Feel free to tell me which of these (or any other) youâ€™d like to explore, and we can dive right in!\n"
     ]
    }
   ],
   "source": [
    "model_1 = load_llm()\n",
    "extracted_answer = give_message(model_1,\"What are some of your use cases?\")\n",
    "print(extracted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7396097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have the basic llm functionality sorted. Can move onto adding agents with CrewAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df8be7",
   "metadata": {},
   "source": [
    "<h4>CrewAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea52df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from load_keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04101b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key_path = Path('keys/open_ai.json')\n",
    "openai_key = load_openai_key(openai_key_path)\n",
    "os.environ['OPENAI_API_KEY'] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f04826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_crew(llm):\n",
    "    researcher = Agent(\n",
    "        role=\"Researcher\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Retrieve and compile evidence using the provided LLM as the sole knowledge source (do NOT call external/local tools).\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    writer = Agent(\n",
    "        role=\"Content Writer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Write a structured answer grounded in the evidence produced by the Researcher (LLM).\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    critic = Agent(\n",
    "        role=\"Reviewer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Check the answer for unsupported claims, missing info, and clarity against the Researcher's evidence.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    t1 = Task(\n",
    "        description=(\n",
    "            \"Research this query using only the LLM: {query}\\nReturn bullet findings.\" # It's important to add the specific variable containing the query hereQ!!\n",
    "        ),\n",
    "        expected_output=\"A bullet list of findings derived from the LLM only.\",\n",
    "        agent=researcher,\n",
    "    )\n",
    "\n",
    "    t2 = Task(\n",
    "        description=(\n",
    "            \"Write the answer. Use the Researcher's findings as the source.\"\n",
    "        ),\n",
    "        expected_output=\"A Markdown response mapped to the Researcher's findings.\",\n",
    "        agent=writer,\n",
    "        context=[t1],\n",
    "    )\n",
    "\n",
    "    t3 = Task(\n",
    "        description=(\n",
    "            \"Critique the answer against the Researcher's response. List issues and provide fix instructions.\"\n",
    "        ),\n",
    "        expected_output=\"A list of issues found plus concrete fix instructions.\",\n",
    "        agent=critic,\n",
    "        context=[t1, t2],\n",
    "    )\n",
    "\n",
    "    t4 = Task(description=(\n",
    "            \"Consider the issues and fix instructions provided by the critic and write a final answer to be outputted to the user\"\n",
    "        ),\n",
    "        expected_output=\"A Final answer, written in markdown, which considers the points raised by the critic\",\n",
    "        agent=writer,\n",
    "        context=[t1, t2, t3],)\n",
    "\n",
    "    return Crew(\n",
    "        agents=[researcher, writer, critic],\n",
    "        tasks=[t1, t2, t3, t4],\n",
    "        process=Process.sequential,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "llm_for_crew = LLM(\n",
    "    model=\"groq/openai/gpt-oss-120b\",\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "test_crew = build_test_crew(llm=llm_for_crew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91af7b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## How Scientists Determine the Age of Earth â€“â€¯Aâ€¯4.54â€¯Ga Estimate  \n",
      "\n",
      "The current scientific consensus is that **Earth is aboutâ€¯4.54â€¯Ga old** (whereâ€¯Gaâ€¯=â€¯billion years), with an overall uncertainty of roughly **Â±â€¯0.05â€¯Ga** (Â±â€¯50â€¯million years). This value is **not a direct measurement of Earth itself**; it is **inferred** from the ages of the oldest Solarâ€‘System solids and from a suite of independent chronometers. Below is a structured synthesis of the principal data sets that underpin this age, together with the logical steps that connect them to the final figure.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Radiometric Dating of Primitive Meteorites â€“ The Primary Benchmark  \n",
      "\n",
      "| Method | Sample | Age (Ga) | Uncertainty (Ga) | Why it matters |\n",
      "|--------|--------|----------|------------------|----------------|\n",
      "| **Uâ€“Pb (Uraniumâ€“Lead)** on **Calciumâ€‘Aluminumâ€‘Rich Inclusions (CAIs)** | Primitive chondritic meteorites (e.g., CV, CO) | **4.567** | **Â±â€¯0.002** | CAIs are the oldest solid condensates that formed in the solar nebula; they set the â€œtimeâ€‘zeroâ€ for the Solar System. |\n",
      "\n",
      "> **Inference step:** Because CAIs preâ€‘date planetary accretion, Earthâ€™s age is **not measured directly**. Subtracting the time required for planetesimal growth and core formation (â‰ˆâ€¯20â€“30â€¯Ma) from the CAI age yields the commonly quoted **4.54â€¯Ga** value.  \n",
      "\n",
      "**Key references:** Amelinâ€¯etâ€¯al.â€¯2002; Dalrympleâ€¯1991; Connellyâ€¯etâ€¯al.â€¯2012.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Direct Radiometric Ages from Earthâ€™s Oldest Minerals  \n",
      "\n",
      "- **Zircon (Uâ€“Pb) from the Jack Hills, Western Australia**  \n",
      "  - Oldest individual crystals: **4.40â€¯Ga** (concordia ages).  \n",
      "  - These zircons record the existence of a solid continental crust by at least 4.40â€¯Ga, implying that Earthâ€™s surface cooled enough for mineral crystallisation within ~100â€¯Ma of Solarâ€‘System formation.  \n",
      "\n",
      "**Uncertainty considerations:**  \n",
      "  - **Lead loss** and metamictisation can shift ages younger; the concordiaâ€‘discordia method is used to correct for this.  \n",
      "  - Analytical precision for modern TIMS/ICPâ€‘MS is â‰ˆâ€¯Â±â€¯0.01â€¯Ga, but systematic uncertainties dominate the lowerâ€‘bound interpretation.  \n",
      "\n",
      "**Key reference:** Nisbetâ€¯&â€¯Fowlerâ€¯2014.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Lunar Sample Ages â€“ An Independent Check  \n",
      "\n",
      "| Isotopic System | Representative Oldest Age (Ga) | Typical Age Range (Ga) | Interpretation |\n",
      "|-----------------|-------------------------------|------------------------|----------------|\n",
      "| **Uâ€“Pb** on lunar anorthosite (highâ€‘land crust) | **4.45** | 4.5â€¯â€“â€¯3.2 | Direct crystallisation age of the oldest lunar crust; provides a lower bound that is within ~100â€¯Ma of the CAI age. |\n",
      "| **Rbâ€‘Sr** | 4.5 | 4.5â€¯â€“â€¯3.2 | Records magmatic events and crust formation. |\n",
      "| **Smâ€‘Nd** | 4.5 | 4.5â€¯â€“â€¯3.2 | Consistent with early differentiation of the Moon. |\n",
      "\n",
      "Because the Moon is thought to have formed **within ~30â€¯Ma of Earth** (giantâ€‘impact hypothesis), the similarity of lunar ages to the CAI age reinforces the **~4.5â€¯Ga** age for Earth.\n",
      "\n",
      "**Uncertainty considerations:**  \n",
      "  - Impactâ€‘induced resetting can partially erase older signatures; highâ€‘precision Uâ€“Pb on pristine highâ€‘land samples minimizes this effect.  \n",
      "  - Typical analytical 1â€‘Ïƒ errors are Â±â€¯0.01â€“0.02â€¯Ga, with additional systematic components from isotope fractionation corrections.  \n",
      "\n",
      "**Key reference:** Touboulâ€¯etâ€¯al.â€¯2007.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Helioseismic and Solarâ€‘Evolution Models  \n",
      "\n",
      "- **Helioseismology** (solar interior oscillations) tightly constrains the Sunâ€™s internal structure, composition, and age.  \n",
      "- Solarâ€‘evolution calculations calibrated to helioseismic data give a **Solarâ€‘System age of â‰ˆâ€¯4.57â€¯Ga**.  \n",
      "\n",
      "> **Reference:** Bahcall, Pinsonneault & Basuâ€¯2001, *The Astrophysical Journal*, 555, 990â€‘1012.  \n",
      "\n",
      "Because Earth and the other planets condensed from the same protoplanetary disk, this modelâ€‘based age provides an **independent, physicsâ€‘based validation** of the radiometric ages.\n",
      "\n",
      "**Uncertainty considerations:**  \n",
      "  - Dependence on opacity tables, solar metallicity, and nuclear reaction rates introduces systematic uncertainties of â‰ˆâ€¯Â±â€¯0.02â€¯Ga.  \n",
      "\n",
      "---\n",
      "\n",
      "### 5. Chronology of Planetary Differentiation â€“ Hfâ€‘W Systematics  \n",
      "\n",
      "- **Hafniumâ€‘Tungsten (Hfâ€‘W) isotopes** trace core formation: Hf stays in the silicate mantle while W partitions into metal.  \n",
      "- Hfâ€‘W data indicate that **Earthâ€™s core segregated 30â€“50â€¯Ma after Solarâ€‘System formation**.  \n",
      "- Consequently, the bulk of Earthâ€™s mass was already assembled by **â‰ˆâ€¯4.5â€¯Ga**, matching the CAIâ€‘derived age.  \n",
      "\n",
      "**Uncertainty considerations:**  \n",
      "  - Assumptions about the initial ^182Hf/^180Hf ratio and the homogeneity of the early nebula contribute â‰ˆâ€¯Â±â€¯0.03â€¯Ga to the coreâ€‘formation age.  \n",
      "\n",
      "**Key reference:** Touboulâ€¯etâ€¯al.â€¯2007.\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Combined Uncertainty  \n",
      "\n",
      "Each chronometer contributes both **statistical (analytical) errors** and **systematic components** (e.g., earlyâ€‘nebula heterogeneity, model dependence). To obtain the communityâ€‘wide error envelope:\n",
      "\n",
      "1. **Assign 1â€‘Ïƒ uncertainties** to each individual age (including systematic terms).  \n",
      "2. **Perform a weightedâ€‘mean Monteâ€‘Carlo propagation** that samples each distribution thousands of times.  \n",
      "3. **Derive the resulting 1â€‘Ïƒ spread** of the combined age distribution.  \n",
      "\n",
      "The outcome is an overall **Â±â€¯0.05â€¯Ga** envelope. **Importantly, this figure reflects the consensus value that incorporates systematic uncertainties; it is not a strict statistical 1â€‘Ïƒ interval from a single dataset.**\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Consistency Across the Inner Solar System  \n",
      "\n",
      "Isotopic studies of **Mars, Venus, and Mercury** (via meteorites, spacecraft analyses, and remote spectroscopy) yield formation ages **â‰ˆâ€¯4.5â€¯Ga** as well. The synchrony of these ages supports a **rapid, contemporaneous accretion of the inner planets** within the first ~100â€¯Ma of Solarâ€‘System history.\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Geological Implications of a 4.54â€¯Ga Earth  \n",
      "\n",
      "| Eon | Approximate Time Span | Major Processes |\n",
      "|-----|----------------------|-----------------|\n",
      "| **Hadean** | 4.54â€¯â€“â€¯4.0â€¯Ga | Core formation, magmaâ€‘ocean solidification, early crust (supported by Jack Hills zircon ages up to 4.40â€¯Ga). |\n",
      "| **Archean** | 4.0â€¯â€“â€¯2.5â€¯Ga | Stabilisation of continental nuclei, emergence of life (stromatolites). |\n",
      "| **Proterozoic** | 2.5â€¯â€“â€¯0.54â€¯Ga | Atmospheric oxygenation, supercontinent cycles. |\n",
      "| **Phanerozoic** | 0.54â€¯Gaâ€¯â€“â€¯present | Diversification of multicellular life, modern plateâ€‘tectonic regime. |\n",
      "\n",
      "Thus, the **~4.5â€¯billionâ€‘year timescale** provides the temporal framework for all subsequent geological, atmospheric, and biological evolution on Earth.\n",
      "\n",
      "---\n",
      "\n",
      "## 9. Key References (consistent citation style)\n",
      "\n",
      "- **Amelin, Y., etâ€¯al. (2002).** Lead isotopic ages of chondrules and CAIs. *Science*, 297, 1678â€‘1683.  \n",
      "- **Bahcall, J.â€¯N., Pinsonneault, M.â€¯H., & Basu, S. (2001).** Solar models: current epoch and time dependences, neutrinos, and helioseismology. *The Astrophysical Journal*, 555, 990â€‘1012.  \n",
      "- **Bouvier, A., & Wadhwa, M. (2010).** The age of the Solar System reâ€‘evaluated by the Pbâ€“Pb chronology of meteorites. *Nature Geoscience*, 3, 723â€‘726.  \n",
      "- **Connelly, J.â€¯N., etâ€¯al. (2012).** The absolute chronology and thermal history of the early Solar System. *Science*, 338, 651â€‘655.  \n",
      "- **Dalrymple, G.â€¯B. (1991).** *The Age of the Earth*. Stanford University Press.  \n",
      "- **Nisbet, E.â€¯G., & Fowler, A.â€¯C. (2014).** The age of the Earth. *Geochimica et Cosmochimica Acta*, 140, 236â€‘247.  \n",
      "- **Touboul, M., etâ€¯al. (2007).** Hfâ€‘W chronometry of the Earthâ€‘Moon system. *Nature*, 447, 720â€‘723.  \n",
      "\n",
      "These works, together with the broader peerâ€‘reviewed literature on isotopic geochronology, underpin the **4.54â€¯Â±â€¯0.05â€¯Ga** age currently accepted for Earth.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Trace Batch Finalization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> âœ… Trace batch finalized with session ID: 711f30c6-c4dd-4aae-ba5e-ba61223e4d4d                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> ğŸ”— View here:                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> https://app.crewai.com/crewai_plus/ephemeral_trace_batches/711f30c6-c4dd-4aae-ba5e-ba61223e4d4d?access_code=TRA <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> CE-e3b137a15f                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> ğŸ”‘ Access Code: TRACE-e3b137a15f                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Trace Batch Finalization \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m âœ… Trace batch finalized with session ID: 711f30c6-c4dd-4aae-ba5e-ba61223e4d4d                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m ğŸ”— View here:                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m https://app.crewai.com/crewai_plus/ephemeral_trace_batches/711f30c6-c4dd-4aae-ba5e-ba61223e4d4d?access_code=TRA \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m CE-e3b137a15f                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m ğŸ”‘ Access Code: TRACE-e3b137a15f                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the crew:\n",
    "initial_user_query = \"How old is the planet?\"\n",
    "\n",
    "result = test_crew.kickoff(inputs={\"query\": initial_user_query})\n",
    "print(result)\n",
    "# The final answer here mentions the critque mainly..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1fb4b7",
   "metadata": {},
   "source": [
    "<h4>Combining it with the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e464e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the local search tool that the CrewAI will use, giving the tool the loaded vecstore:\n",
    "from typing import Type, List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from crewai.tools import BaseTool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from docstore_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da91a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FAISS store from 'vectorstore' with 549 document(s).\n"
     ]
    }
   ],
   "source": [
    "# Local search tool for the crew to use:\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from crewai.tools import BaseTool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "class LocalSearchArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"User question\")\n",
    "    k: int = Field(6, ge=1, le=20, description=\"Top-k chunks\")\n",
    "\n",
    "class LocalFAISSSearchTool(BaseTool):\n",
    "    name: str = \"local_search\"\n",
    "    description: str = \"Search the local FAISS vectorstore and return relevant chunks with source metadata.\"\n",
    "    args_schema: Type[BaseModel] = LocalSearchArgs\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    store: FAISS\n",
    "\n",
    "    def _run(self, query: str, k: int = 6) -> List[Dict[str, Any]]:\n",
    "        docs = self.store.similarity_search(query, k=k)\n",
    "        out = []\n",
    "        for i, d in enumerate(docs, start=1):\n",
    "            out.append({\n",
    "                \"id\": f\"L-{i:04d}\",\n",
    "                \"text\": d.page_content,\n",
    "                \"source\": d.metadata.get(\"source\", \"\"),\n",
    "                \"page\": d.metadata.get(\"page\", None),\n",
    "                \"content_hash\": d.metadata.get(\"content_hash\", None),\n",
    "            })\n",
    "        return out\n",
    "    \n",
    "# Loading the store:\n",
    "store,document_list = load_docstore_from_dir()\n",
    "local_tool = LocalFAISSSearchTool(store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a225f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing it with a crew:\n",
    "\n",
    "def build_local_crew(llm, local_tool):\n",
    "    researcher = Agent(\n",
    "        role=\"Researcher\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Retrieve and compile evidence from the local FAISS store using the local_search tool.\",\n",
    "        llm=llm,\n",
    "        tools=[local_tool],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    writer = Agent(\n",
    "        role=\"Content Writer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Write a structured answer grounded ONLY in the Researcher's retrieved chunks. Cite chunk IDs.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    critic = Agent(\n",
    "        role=\"Reviewer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Check the answer for unsupported claims and missing info against the retrieved chunks.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    t1 = Task(\n",
    "        description=(\n",
    "            \"Query: {query}\\n\"\n",
    "            \"1) Call local_search(query={query}, k=6).\\n\"\n",
    "            \"2) Return:\\n\"\n",
    "            \"- A short 'Evidence' list\\n\"\n",
    "            \"- Bullet 'Findings' where EACH bullet cites one or more evidence IDs.\\n\"\n",
    "        ),\n",
    "        expected_output=\"Evidence list + Findings with citations like [L-0001].\",\n",
    "        agent=researcher,\n",
    "    )\n",
    "\n",
    "    t2 = Task(\n",
    "        description=(\n",
    "            \"Write a Markdown answer to: {query}\\n\"\n",
    "            \"Use ONLY the Evidence/Findings from the Researcher.\\n\"\n",
    "            \"Every major claim must include citations like [L-0001].\"\n",
    "        ),\n",
    "        expected_output=\"Markdown answer with evidence-ID citations.\",\n",
    "        agent=writer,\n",
    "        context=[t1],\n",
    "    )\n",
    "\n",
    "    t3 = Task(\n",
    "        description=(\n",
    "            \"Critique the Markdown answer for: {query}\\n\"\n",
    "            \"Flag any claim without a supporting citation from [L-xxxx]. Provide fix instructions.\"\n",
    "        ),\n",
    "        expected_output=\"Issues + fix instructions.\",\n",
    "        agent=critic,\n",
    "        context=[t1, t2],\n",
    "    )\n",
    "\n",
    "    t4 = Task(description=(\n",
    "            \"Consider the issues and fix instructions provided by the critic and write a final answer to be outputted to the user\"\n",
    "        ),\n",
    "        expected_output=\"A Final answer, written in markdown, which considers the points raised by the critic\",\n",
    "        agent=writer,\n",
    "        context=[t1, t2, t3],)\n",
    "\n",
    "    return Crew(\n",
    "        agents=[researcher, writer, critic],\n",
    "        tasks=[t1, t2, t3,t4],\n",
    "        process=Process.sequential,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d102d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 2758.64it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-small-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'llm_call_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'agent_execution_completed'\u001b[0m closed \u001b[32m'llm_call_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'agent_execution_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'task_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'task_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'task_completed'\u001b[0m closed \u001b[32m'agent_execution_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'task_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'crew_kickoff_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'task_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'crew_kickoff_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'crew_kickoff_completed'\u001b[0m closed \u001b[32m'task_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'crew_kickoff_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Most Important Reactions Used in Naturalâ€‘Product Synthesis  \n",
      "\n",
      "| Reaction class | Why it is important in total synthesis | Representative examples |\n",
      "|----------------|----------------------------------------|--------------------------|\n",
      "| **Multicomponent reactions (MCRs)** â€“ Mannich, Passerini, Ugi, Biginelli, etc. | Provide rapid, convergent access to highly functionalized intermediates, dramatically shortening synthetic sequences. | MCRs are employed to construct alkaloid cores and peptidomimetic natural productsâ€¯[Lâ€‘0001]. |\n",
      "| **(Intramolecular) Dielsâ€‘Alder (IMDA) and tandem Dielsâ€‘Alder (TADA) cycloadditions** | Pericyclic reactions that forge multiple Câ€“C bonds and stereocenters in a single step, enabling the construction of polycyclic frameworks typical of terpenoids, alkaloids and polyketides. | IMDA and TADA cyclizations are widely used to build polycyclic terpenoid and alkaloid frameworksâ€¯[Lâ€‘0002, Lâ€‘0004]. |\n",
      "| **Radicalâ€‘mediated transformations** â€“ especially tandem intramolecular cyclizationâ€‘alkylation | Allow Câ€“C bond formation under mild, often neutral conditions; the radical nature tolerates diverse functional groups and can generate strained or congested motifs that are difficult to access by polar pathways. | Radical cyclizationâ€‘alkylation sequences have been applied to assemble complex carbon skeletons in naturalâ€‘product targetsâ€¯[Lâ€‘0003]. |\n",
      "| **Sonogashira crossâ€‘coupling** | A versatile palladiumâ€‘copper mediated Câ€“C bondâ€‘forming reaction that efficiently installs conjugated alkyne (enyne) fragments, supporting convergent assembly of highly unsaturated natural products. | Sonogashira coupling efficiently installs enyne motifs in naturalâ€‘product targetsâ€¯[Lâ€‘0005]. |\n",
      "| **Photoredox catalysis** | Uses visible light to generate radicals in a controlled, mild fashion, opening new disconnections for the construction of strained rings, heterocycles and densely functionalized scaffolds. | Photoredoxâ€‘driven radical processes enable the synthesis of highly functionalized naturalâ€‘product architecturesâ€¯[Lâ€‘0006]. |\n",
      "\n",
      "### 1. Multicomponent Reactions (MCRs)  \n",
      "MCRs combine three or more building blocks in a single operation, delivering complex, highly functionalized intermediates that can be directly elaborated into naturalâ€‘product targets. This efficiency makes them among the most valuable tools in modern synthesisâ€¯[Lâ€‘0001].\n",
      "\n",
      "### 2. Intramolecular & Tandem Dielsâ€‘Alder Cycloadditions  \n",
      "The intramolecular Dielsâ€‘Alder (IMDA) and tandem Dielsâ€‘Alder (TADA) reactions are cornerstone pericyclic strategies for assembling sixâ€‘membered carbocycles and polycyclic skeletons found in many naturalâ€‘product families. Their concerted nature sets multiple stereocenters in one step, providing excellent stereochemical controlâ€¯[Lâ€‘0002, Lâ€‘0004].\n",
      "\n",
      "### 3. Radicalâ€‘Mediated Transformations  \n",
      "Tandem intramolecular cyclizationâ€‘alkylation sequences enable the construction of carbon frameworks under gentle conditions, often tolerating sensitive functional groups and delivering intricate architectures with high efficiencyâ€¯[Lâ€‘0003].\n",
      "\n",
      "### 4. Sonogashira Coupling  \n",
      "This palladiumâ€‘copper crossâ€‘coupling efficiently joins aryl or vinyl halides with terminal alkynes, furnishing enyne fragments that are prevalent in bioactive natural products and allowing convergent, lateâ€‘stage functionalizationâ€¯[Lâ€‘0005].\n",
      "\n",
      "### 5. Photoredox Catalysis  \n",
      "Visibleâ€‘lightâ€‘driven photoredox processes have emerged as a powerful platform for generating radicals in a controlled manner, enabling the assembly of strained or highly functionalized structures that were previously inaccessible or required harsh conditionsâ€¯[Lâ€‘0006].\n",
      "\n",
      "## Conclusion  \n",
      "The reactions that dominate contemporary naturalâ€‘product synthesis are those that combine **high step economy**, **stereochemical precision**, and **functionalâ€‘group tolerance**. Accordingly, the most important classes are:\n",
      "\n",
      "- Multicomponent reactionsâ€¯[Lâ€‘0001]  \n",
      "- Intramolecular/tandem Dielsâ€‘Alder cycloadditionsâ€¯[Lâ€‘0002, Lâ€‘0004]  \n",
      "- Radicalâ€‘mediated cyclizationsâ€¯[Lâ€‘0003]  \n",
      "- Sonogashira crossâ€‘couplingsâ€¯[Lâ€‘0005]  \n",
      "- Photoredoxâ€‘catalyzed transformationsâ€¯[Lâ€‘0006]  \n",
      "\n",
      "These tools are repeatedly cited as pivotal across a wide range of total syntheses, forming the backbone of modern strategies for building complex natural products.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Trace Batch Finalization \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m âœ… Trace batch finalized with session ID:                                    \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m defb1b24-7294-4382-badc-c6f2a7d98811                                         \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m                                                                              \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”— View here:                                                                \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m https://app.crewai.com/crewai_plus/ephemeral_trace_batches/defb1b24-7294-438 \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m 2-badc-c6f2a7d98811?access_code=TRACE-d001094035                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”‘ Access Code: TRACE-d001094035                                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "local_crew = build_local_crew(llm_for_crew, local_tool)\n",
    "local_query = \"What are the most important reactions used in natural product synthesis?\"\n",
    "local_result = local_crew.kickoff(inputs={\"query\": local_query})\n",
    "print(local_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e71d75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have the Crew using the local_search. Next step is to implement it with tavily for internet searching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42162c5e",
   "metadata": {},
   "source": [
    "<h4>tavily (internet search):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43128aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tavily tool:\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21a5bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"Search query\")\n",
    "    max_results: int = Field(5, ge=1, le=10, description=\"Number of results\")\n",
    "    search_depth: str = Field(\"basic\", description=\"basic or advanced\")\n",
    "\n",
    "class TavilyWebSearchTool(BaseTool):\n",
    "    name: str = \"web_search\"\n",
    "    description: str = \"Search the web via Tavily and return relevant snippets with URLs for citation.\"\n",
    "    args_schema: Type[BaseModel] = WebSearchArgs\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    api_key: str\n",
    "    client: TavilyClient | None = None\n",
    "\n",
    "    def model_post_init(self, __context):\n",
    "        if self.client is None:\n",
    "            self.client = TavilyClient(api_key=self.api_key)\n",
    "\n",
    "    def _run(self, query: str, max_results: int = 5, search_depth: str = \"basic\") -> List[Dict[str, Any]]:\n",
    "        res = self.client.search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            search_depth=search_depth,\n",
    "        )\n",
    "\n",
    "        out: List[Dict[str, Any]] = []\n",
    "        for i, r in enumerate(res.get(\"results\", []), start=1):\n",
    "            out.append({\n",
    "                \"id\": f\"W-{i:04d}\",\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"url\": r.get(\"url\", \"\"),\n",
    "                \"text\": r.get(\"content\", \"\") or r.get(\"snippet\", \"\"),\n",
    "                \"source\": \"tavily\",\n",
    "                \"score\": r.get(\"score\", None),\n",
    "            })\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "996acf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tavily API key:\n",
    "from load_keys import *\n",
    "p = Path(\"keys/tavily.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3883b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = load_tavily_key(p)\n",
    "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d916e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_tool = TavilyWebSearchTool(api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35c79eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing it with a crew:\n",
    "def build_crew(llm, local_tool,web_tool):\n",
    "    researcher = Agent(\n",
    "        role=\"Researcher\",\n",
    "        backstory=\"You gather evidence. You MUST use tools. You never answer from memory.\",\n",
    "        goal=\"Retrieve and compile evidence from local FAISS first, then Tavily web search only if needed.\",\n",
    "        llm=llm,\n",
    "        tools=[local_tool, web_tool],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    writer = Agent(\n",
    "        role=\"Content Writer\",\n",
    "        backstory=\"You write clear answers grounded strictly in evidence provided.\",\n",
    "        goal=\"Write a structured answer using ONLY the Researcher's evidence. Cite evidence IDs.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    critic = Agent(\n",
    "        role=\"Reviewer\",\n",
    "        backstory=\"You are strict about grounding. No evidence = no claim.\",\n",
    "        goal=\"Check the draft for unsupported claims, missing coverage, and clarity against the evidence.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    reviser = Agent(\n",
    "        role=\"Reviser\",\n",
    "        backstory=\"You apply reviewer feedback and output the final answer.\",\n",
    "        goal=\"Revise the draft to fully comply with evidence and reviewer notes. Output final Markdown only.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    t1 = Task(\n",
    "        description=(\n",
    "            \"User query: {query}\\n\\n\"\n",
    "            \"1) ALWAYS call local_search(query={query}, k=6).\\n\"\n",
    "            \"2) Decide if web search is necessary:\\n\"\n",
    "            \"   - If the query asks for recency (latest/today/current/news) OR\\n\"\n",
    "            \"   - Local evidence is insufficient/weak (few relevant chunks)\\n\"\n",
    "            \"   then call web_search(query={query}, max_results=5, search_depth='basic').\\n\\n\"\n",
    "            \"Return two sections:\\n\"\n",
    "            \"A) EVIDENCE (list): each item must include an ID [L-xxxx] or [W-xxxx], plus source/url/page and a 1-sentence summary.\\n\"\n",
    "            \"B) FINDINGS (bullets): each bullet must cite one or more evidence IDs.\\n\"\n",
    "        ),\n",
    "        expected_output=\"Evidence list + Findings with citations like [L-0001] and [W-0002].\",\n",
    "        agent=researcher,\n",
    "    )\n",
    "\n",
    "    t2 = Task(\n",
    "        description=(\n",
    "            \"Write a Markdown answer to: {query}\\n\"\n",
    "            \"Use ONLY the Researcher's EVIDENCE/FINDINGS.\\n\"\n",
    "            \"Every major claim must have citations like [L-0001] or [W-0002].\\n\"\n",
    "            \"If evidence is insufficient, say so and suggest what else is needed.\\n\"\n",
    "        ),\n",
    "        expected_output=\"Markdown answer with evidence-ID citations.\",\n",
    "        agent=writer,\n",
    "        context=[t1],\n",
    "    )\n",
    "\n",
    "    t3 = Task(\n",
    "        description=(\n",
    "            \"Critique the draft answer for: {query}\\n\"\n",
    "            \"Check that:\\n\"\n",
    "            \"- All major claims have citations.\\n\"\n",
    "            \"- No claim contradicts the evidence.\\n\"\n",
    "            \"- The answer is complete and clear.\\n\"\n",
    "            \"Output: (1) Issues list, (2) Concrete fix instructions.\\n\"\n",
    "        ),\n",
    "        expected_output=\"Issues + fix instructions.\",\n",
    "        agent=critic,\n",
    "        context=[t1, t2],\n",
    "    )\n",
    "\n",
    "    t4 = Task(\n",
    "        description=(\n",
    "            \"Revise the draft answer for: {query}\\n\"\n",
    "            \"Apply ALL fix instructions from the Reviewer.\\n\"\n",
    "            \"Keep citations. Output ONLY the final Markdown answer.\\n\"\n",
    "        ),\n",
    "        expected_output=\"Final Markdown answer only.\",\n",
    "        agent=reviser,\n",
    "        context=[t1, t2, t3],\n",
    "    )\n",
    "\n",
    "    return Crew(\n",
    "        agents=[researcher, writer, critic, reviser],\n",
    "        tasks=[t1, t2, t3, t4],\n",
    "        process=Process.sequential,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31bcbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_tool = TavilyWebSearchTool(api_key=tavily_api_key)\n",
    "local_tool = LocalFAISSSearchTool(store=store)\n",
    "overall_crew = build_crew(llm_for_crew,local_tool,internet_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "184353a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'llm_call_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'agent_execution_completed'\u001b[0m closed \u001b[32m'llm_call_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'agent_execution_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'task_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'task_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'task_completed'\u001b[0m closed \u001b[32m'agent_execution_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'task_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'crew_kickoff_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'task_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'crew_kickoff_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'crew_kickoff_completed'\u001b[0m closed \u001b[32m'task_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'crew_kickoff_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday,â€¯Februaryâ€¯9,â€¯2026ã€Wâ€‘0001ã€‘ã€Wâ€‘0002ã€‘ã€Wâ€‘0003ã€‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Trace Batch Finalization \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m âœ… Trace batch finalized with session ID:                                    \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m 08c62313-80d5-45e6-b715-1f7afddfe956                                         \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m                                                                              \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”— View here:                                                                \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m https://app.crewai.com/crewai_plus/ephemeral_trace_batches/08c62313-80d5-45e \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m 6-b715-1f7afddfe956?access_code=TRACE-7c1678a9c7                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”‘ Access Code: TRACE-7c1678a9c7                                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"This is a test question. What is today's date?\"\n",
    "result = overall_crew.kickoff(inputs={\"query\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "623956d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'llm_call_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'agent_execution_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'agent_execution_completed'\u001b[0m closed \u001b[32m'llm_call_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'agent_execution_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'task_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'llm_call_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'task_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'task_completed'\u001b[0m closed \u001b[32m'llm_call_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'task_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>CrewAIEventsBus<span style=\"font-weight: bold\">]</span> Warning: Event pairing mismatch. <span style=\"color: #008000; text-decoration-color: #008000\">'crew_kickoff_completed'</span> closed <span style=\"color: #008000; text-decoration-color: #008000\">'llm_call_started'</span> <span style=\"font-weight: bold\">(</span>expected \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'crew_kickoff_started'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mCrewAIEventsBus\u001b[1m]\u001b[0m Warning: Event pairing mismatch. \u001b[32m'crew_kickoff_completed'\u001b[0m closed \u001b[32m'llm_call_started'\u001b[0m \u001b[1m(\u001b[0mexpected \n",
       "\u001b[32m'crew_kickoff_started'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top World News Headlines (9â€¯Februaryâ€¯2026)\n",
      "\n",
      "- **â€œTwenty years for Jimmyâ€¯Lai is a â€˜death sentence,â€™ son saysâ€** â€“ Hongâ€¯Kong critic Jimmyâ€¯Lai receives a 20â€‘year jail term, sparking international outcryã€Wâ€‘0001ã€‘.  \n",
      "- **â€œWaymo goes fully autonomous in Nashvilleâ€** â€“ Waymo launches a completely driverâ€‘less rideâ€‘hailing service in Nashville, Tennesseeã€Wâ€‘0005ã€‘.  \n",
      "- **â€œKroger taps former Walmart exec to lead US grocer, shares riseâ€** â€“ Kroger appoints a former Walmart executive as CEO, sending its stock higherã€Wâ€‘0006ã€‘.  \n",
      "- **â€œAir Canada suspends Cuba flights as island set to run out of jet fuelâ€** â€“ Air Canada halts all flights to Cuba amid an imminent jetâ€‘fuel shortage on the islandã€Wâ€‘0007ã€‘.  \n",
      "- **â€œScenes from Super Bowlâ€¯LX â€“ Seattle Seahawks beat New England 29â€‘13â€** â€“ The Seattle Seahawks defeat the New England Patriots 29â€‘13 in Super Bowlâ€¯LXã€Wâ€‘0008ã€‘.  \n",
      "- **â€œBroken medals spark investigation from Milano Games organizersâ€** â€“ An investigation is launched after several Olympic medals were found broken during the Milanoâ€‘Cortina Winter Gamesã€Wâ€‘0004ã€‘.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Trace Batch Finalization \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m âœ… Trace batch finalized with session ID:                                    \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m deda1bb9-e351-4f65-8d09-6911204ef3e2                                         \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m                                                                              \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”— View here:                                                                \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m https://app.crewai.com/crewai_plus/ephemeral_trace_batches/deda1bb9-e351-4f6 \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m 5-8d09-6911204ef3e2?access_code=TRACE-aaf0bb5de4                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”‘ Access Code: TRACE-aaf0bb5de4                                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"List the top news headlines from around the world toady\"\n",
    "result = overall_crew.kickoff(inputs={\"query\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a517b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily seems to be working! When we ask for current info (date/news), we get accurate answers.\n",
    "# Next steps are to extract the classes/functions from this notebook into an importable module script to be used by Streamlit for the frontend..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c029a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
