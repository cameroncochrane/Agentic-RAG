{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3316f88a",
   "metadata": {},
   "source": [
    "<h2>Agentic RAG App: Groq LLM</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e56ab",
   "metadata": {},
   "source": [
    "<h3>LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c845f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cameroncochrane/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# LangChain has a Groq chat model integration:\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a03ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API groq API key:\n",
    "from pathlib import Path\n",
    "# Bespoke API key loader functions:\n",
    "from load_keys import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc9c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"keys/groq.json\")\n",
    "groq_api_key = load_groq_key(p)\n",
    "os.environ['GROQ_API_KEY'] = groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9814ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model:\n",
    "model = ChatGroq(\n",
    "            model=\"openai/gpt-oss-120b\",\n",
    "            temperature=0.2,\n",
    "            max_retries=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22262716",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = [(\"human\",\"hello, how are you?\")]\n",
    "answer_1 = model.invoke(initial_message) # .invoke to send a message to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a66c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing great, thank you for asking. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "extracted_message = answer_1.content # x.content returns the message for the user.\n",
    "print(extracted_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c939dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I donâ€™t have the ability to browse the web or access realâ€‘time internet content. My responses are based on the information I was trained on, which goes up through Septemberâ€¯2021 (with a limited knowledge update through 2024). If you need the most current data or something that requires live lookup, youâ€™ll need to check a reliable source directly.\n"
     ]
    }
   ],
   "source": [
    "internet_message = [(\"human\",\"Do you have internet access?\")]\n",
    "internet_answer = model.invoke(internet_message)\n",
    "print(internet_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945c233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm(model_type:str = 'openai/gpt-oss-120b',api_key_path:str = \"keys/groq.json\"):\n",
    "    \n",
    "    p = Path(api_key_path)\n",
    "\n",
    "    groq_api_key = load_groq_key(p)\n",
    "    os.environ['GROQ_API_KEY'] = groq_api_key\n",
    "    \n",
    "    model = ChatGroq(\n",
    "            model=model_type,\n",
    "            temperature=0.2,\n",
    "            max_retries=2,\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c705dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_message(model,message):\n",
    "\n",
    "    full_answer = model.invoke(message)\n",
    "    extracted_answer = full_answer.content\n",
    "\n",
    "    return extracted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e383e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Hereâ€™s a quick overview of the many ways people (and businesses) put a language model like me to work:\n",
      "\n",
      "| Category | Typical Use Cases | Example Prompts |\n",
      "|----------|-------------------|-----------------|\n",
      "| **Content Creation** | â€¢ Blog posts, articles, newsletters<br>â€¢ Socialâ€‘media copy, ad headlines, product descriptions<br>â€¢ Scripts for videos, podcasts, webinars | â€œWrite a 600â€‘word blog post about sustainable travel trends in 2024.â€ |\n",
      "| **Creative Writing** | â€¢ Short stories, flash fiction, poetry<br>â€¢ Plot outlines, character bios, worldâ€‘building details<br>â€¢ Dialogue polishing, writerâ€™s block busting | â€œGive me three possible twists for a mystery set in a lunar mining colony.â€ |\n",
      "| **Education & Tutoring** | â€¢ Explaining concepts (math, science, history, etc.)<br>â€¢ Generating practice problems & solutions<br>â€¢ Language learning (vocab, grammar, conversation) | â€œExplain the difference between Newtonâ€™s first and second laws with everyday examples.â€ |\n",
      "| **Programming & Technical Help** | â€¢ Writing/ debugging code snippets in many languages<br>â€¢ Explaining algorithms, data structures, design patterns<br>â€¢ Translating pseudocode to real code, generating unit tests | â€œWrite a Python function that merges two sorted lists in O(n) time.â€ |\n",
      "| **Business & Productivity** | â€¢ Drafting emails, proposals, meeting agendas<br>â€¢ Summarizing long documents, reports, meeting transcripts<br>â€¢ Building outlines for presentations, SOPs, or project plans | â€œSummarize the key takeaways from this 12â€‘page market research report.â€ |\n",
      "| **Data & Analytics Support** | â€¢ Explaining statistical concepts, interpreting results<br>â€¢ Helping design A/B test plans, KPI dashboards<br>â€¢ Generating SQL queries or dataâ€‘cleaning scripts | â€œWrite a SQL query to find customers who made a purchase in the last 30 days but not in the previous 30 days.â€ |\n",
      "| **Customer Support & Chatbots** | â€¢ Drafting FAQ answers, troubleshooting guides<br>â€¢ Simulating roleâ€‘play scenarios for training agents<br>â€¢ Generating polite, onâ€‘brand responses | â€œProvide a friendly response to a user who canâ€™t reset their password.â€ |\n",
      "| **Research & Knowledge Work** | â€¢ Conducting literature reviews, extracting citations<br>â€¢ Factâ€‘checking statements, providing source suggestions<br>â€¢ Generating annotated bibliographies | â€œGive me a brief overview of recent advances in quantum error correction.â€ |\n",
      "| **Translation & Localization** | â€¢ Translating text between many language pairs<br>â€¢ Adapting tone and cultural references for specific audiences<br>â€¢ Proofreading multilingual content | â€œTranslate this product description from English to Japanese, keeping a casual tone.â€ |\n",
      "| **Personal Assistance** | â€¢ Planning trips, itineraries, packing lists<br>â€¢ Generating meal plans, recipes, grocery lists<br>â€¢ Brainstorming gift ideas, hobbies, or selfâ€‘improvement goals | â€œCreate a 7â€‘day itinerary for a family visiting Barcelona with kids under 10.â€ |\n",
      "| **Legal & Compliance (informational only)** | â€¢ Summarizing contract clauses, explaining legal terminology<br>â€¢ Drafting basic templates (NDAs, consent forms) for review by a qualified professional | â€œOutline the main sections that should appear in a standard SaaS subscription agreement.â€ |\n",
      "| **Healthcare (informational only)** | â€¢ Explaining medical concepts in lay terms<br>â€¢ Providing wellness tips, exercise ideas, nutrition basics<br>â€¢ Summarizing research articles (always verify with a professional) | â€œWhat are the typical symptoms of vitamin D deficiency?â€ |\n",
      "| **Entertainment & Games** | â€¢ Generating trivia questions, riddles, puzzles<br>â€¢ Designing tabletopâ€‘RPG encounters, character sheets<br>â€¢ Writing jokes, memes, or socialâ€‘media challenges | â€œCreate a 5â€‘question multipleâ€‘choice quiz about classic cinema.â€ |\n",
      "| **Accessibility** | â€¢ Converting complex text into simpler language<br>â€¢ Generating altâ€‘text descriptions for images (when given a description)<br>â€¢ Providing signâ€‘language glosses or braille transcription guidance | â€œRewrite this paragraph for a 5thâ€‘grade reading level.â€ |\n",
      "\n",
      "### How to Get the Most Out of Me\n",
      "1. **Be specific** â€“ The clearer the prompt, the more targeted the output.  \n",
      "2. **Provide context** â€“ If you have style guidelines, audience details, or constraints, include them.  \n",
      "3. **Iterate** â€“ You can ask for revisions, expansions, or different angles until it fits your needs.  \n",
      "4. **Validate** â€“ For factual, legal, medical, or financial content, always doubleâ€‘check with a qualified source.\n",
      "\n",
      "Feel free to let me know which area interests you most, and I can dive deeper into examples or walk you through a quick demo!\n"
     ]
    }
   ],
   "source": [
    "model_1 = load_llm()\n",
    "extracted_answer = give_message(model_1,\"What are some of your use cases?\")\n",
    "print(extracted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7396097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have the basic llm functionality sorted. Can move onto adding agents with CrewAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df8be7",
   "metadata": {},
   "source": [
    "<h4>CrewAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea52df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from load_keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04101b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key_path = Path('keys/open_ai.json')\n",
    "openai_key = load_openai_key(openai_key_path)\n",
    "os.environ['OPENAI_API_KEY'] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78f04826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_crew(llm):\n",
    "    researcher = Agent(\n",
    "        role=\"Researcher\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Retrieve and compile evidence using the provided LLM as the sole knowledge source (do NOT call external/local tools).\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    writer = Agent(\n",
    "        role=\"Content Writer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Write a structured answer grounded in the evidence produced by the Researcher (LLM).\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    critic = Agent(\n",
    "        role=\"Reviewer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Check the answer for unsupported claims, missing info, and clarity against the Researcher's evidence.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    t1 = Task(\n",
    "        description=(\n",
    "            \"Research this query using only the LLM: {query}\\nReturn bullet findings.\" # It's important to add the specific variable containing the query hereQ!!\n",
    "        ),\n",
    "        expected_output=\"A bullet list of findings derived from the LLM only.\",\n",
    "        agent=researcher,\n",
    "    )\n",
    "\n",
    "    t2 = Task(\n",
    "        description=(\n",
    "            \"Write the answer. Use the Researcher's findings as the source.\"\n",
    "        ),\n",
    "        expected_output=\"A Markdown response mapped to the Researcher's findings.\",\n",
    "        agent=writer,\n",
    "        context=[t1],\n",
    "    )\n",
    "\n",
    "    t3 = Task(\n",
    "        description=(\n",
    "            \"Critique the answer against the Researcher's response. List issues and provide fix instructions.\"\n",
    "        ),\n",
    "        expected_output=\"A list of issues found plus concrete fix instructions.\",\n",
    "        agent=critic,\n",
    "        context=[t1, t2],\n",
    "    )\n",
    "\n",
    "    t4 = Task(description=(\n",
    "            \"Consider the issues and fix instructions provided by the critic and write a final answer to be outputted to the user\"\n",
    "        ),\n",
    "        expected_output=\"A Final answer, written in markdown, which considers the points raised by the critic\",\n",
    "        agent=writer,\n",
    "        context=[t1, t2, t3],)\n",
    "\n",
    "    return Crew(\n",
    "        agents=[researcher, writer, critic],\n",
    "        tasks=[t1, t2, t3, t4],\n",
    "        process=Process.sequential,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "llm_for_crew = LLM(\n",
    "    model=\"groq/openai/gpt-oss-120b\",\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "test_crew = build_test_crew(llm=llm_for_crew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af7b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The Age of the Earth â€“ Evidenceâ€‘Based Consensus (â‰ˆâ€¯4.54â€¯billionâ€¯years)\n",
      "\n",
      "## 1.â€¯Current Scientific Estimate  \n",
      "**The Earth is estimated to beâ€¯4.54â€¯Ga oldâ€¯(Â±â€¯0.05â€¯Ga, i.e., Â±â€¯50â€¯millionâ€¯years).**  \n",
      "\n",
      "---\n",
      "\n",
      "## 2.â€¯Primary Dating Evidence â€“ Ironâ€‘Nickel Meteorites  \n",
      "\n",
      "| Sample | Dating Method | Age (Ga) | Uncertainty | Why it matters |\n",
      "|--------|---------------|----------|-------------|----------------|\n",
      "| **Canyonâ€¯Diablo (ironâ€‘nickel meteorite)** | **Uraniumâ€“lead (Uâ€‘Pb)** | **4.56** | **Â±â€¯0.02** | Because ironâ€‘nickel meteorites have remained chemically closed since condensation, their Uâ€‘Pb clocks record the time of the first solid bodies in the solar system, which is taken as the age of the material from which Earth accreted. This makes the age the **most precise** determination of early solarâ€‘system solids (Jacobsen *etâ€¯al.*,â€¯2008; Amelin *etâ€¯al.*,â€¯2002). |\n",
      "\n",
      "---\n",
      "\n",
      "## 3.â€¯Analytical Techniques  \n",
      "Highâ€‘precision ages are obtained with **thermalâ€‘ionisation mass spectrometry (TIMS)** or **inductivelyâ€‘coupled plasma mass spectrometry (ICPâ€‘MS)**. For each isotopic system an **isochron** is constructed (e.g.,â€¯â¸â·Sr/â¸â¶Srâ€¯vs.â€¯â¸â·Rb/â¸â¶Sr). The slope of the line yields the age, while the intercept gives the initial daughterâ€‘isotope ratio. Careful chemical separation, repeated measurements, and interâ€‘laboratory interâ€‘comparisons keep **analytical uncertainties** to â‰ˆâ€¯Â±â€¯0.02â€¯Ga.\n",
      "\n",
      "---\n",
      "\n",
      "## 4.â€¯Supporting Evidence â€“ Apollo Lunar Samples  \n",
      "\n",
      "| Isotopic System | Typical Age (Ga) | Typical Uncertainty (Ga) |\n",
      "|-----------------|------------------|--------------------------|\n",
      "| **Uâ€‘Pb** | 4.48â€¯â€“â€¯4.52 | Â±â€¯0.03 |\n",
      "| **Smâ€‘Nd** | 4.49â€¯â€“â€¯4.53 | Â±â€¯0.03 |\n",
      "| **Rbâ€‘Sr** | 4.47â€¯â€“â€¯4.51 | Â±â€¯0.04 |\n",
      "\n",
      "All three systems converge on ages of **â‰ˆâ€¯4.5â€¯Ga** for lunar rocks. Because the Moon formed from the same impactâ€‘generated debris disk as Earth, this independent planetary verification corroborates the meteorite ages (Touboul *etâ€¯al.*,â€¯2007).\n",
      "\n",
      "---\n",
      "\n",
      "## 5.â€¯Oldest Terrestrial Minerals  \n",
      "\n",
      "- **Material:** Zircon crystals from the **Jackâ€¯Hills** region, Western Australia.  \n",
      "- **Dating method:** Highâ€‘precision Uâ€‘Pb.  \n",
      "- **Age:** **â‰ˆâ€¯4.40â€¯Ga** (Nemchin *etâ€¯al.*,â€¯2008).  \n",
      "\n",
      "This age demonstrates that a **stable continental crust** existed by ~4.40â€¯Ga, indicating that **coreâ€‘mantleâ€‘crust differentiation** was essentially complete within ~100â€¯millionâ€¯years of solarâ€‘system formation.\n",
      "\n",
      "---\n",
      "\n",
      "## 6.â€¯Convergence of Multiple Isotopic Systems  \n",
      "\n",
      "| Isotopic System | Materials Analyzed | Concordant Age Range (Ga) | Key References |\n",
      "|-----------------|--------------------|---------------------------|----------------|\n",
      "| **Uâ€‘Pb** | Meteorites, lunar rocks, Jackâ€‘Hills zircons | 4.5â€¯â€“â€¯4.6 | Jacobsen *etâ€¯al.*,â€¯2008; Amelin *etâ€¯al.*,â€¯2002 |\n",
      "| **Smâ€‘Nd** | Meteorites, terrestrial rocks | 4.5â€¯â€“â€¯4.6 | Touboul *etâ€¯al.*,â€¯2007 |\n",
      "| **Rbâ€‘Sr** | Meteorites, terrestrial rocks | 4.5â€¯â€“â€¯4.6 | Touboul *etâ€¯al.*,â€¯2007 |\n",
      "\n",
      "The independent decay schemes all point to the same interval, reinforcing the robustness of the age estimate.\n",
      "\n",
      "---\n",
      "\n",
      "## 7.â€¯Helioseismic & Solarâ€‘System Formation Models  \n",
      "\n",
      "Helioseismic measurements of the Sunâ€™s internal **soundâ€‘speed profile**, combined with calibrated **solarâ€‘evolution models**, yield a solar age of **â‰ˆâ€¯4.57â€¯Â±â€¯0.02â€¯Ga** (Bahcall *etâ€¯al.*,â€¯2001). Protoplanetaryâ€‘disk evolution models arrive at a similar formation time of **â‰ˆâ€¯4.6â€¯Ga**. This theoretical age **matches** the radiometric ages from meteorites and lunar samples, providing an independent physicsâ€‘based confirmation.\n",
      "\n",
      "---\n",
      "\n",
      "## 8.â€¯Uncertainty Budget  \n",
      "\n",
      "| Source | Typical Contribution (Ga) |\n",
      "|--------|---------------------------|\n",
      "| **Analytical** (instrument precision, sample preparation) | Â±â€¯0.02 |\n",
      "| **Systematic** (decayâ€‘constant values, isotopic fractionation corrections) | Â±â€¯0.04 |\n",
      "\n",
      "Combined in quadrature, the total uncertainty is **Â±â€¯0.05â€¯Ga** (Â±â€¯50â€¯millionâ€¯years).\n",
      "\n",
      "---\n",
      "\n",
      "## 9.â€¯Cultural / Nonâ€‘Scientific Age Estimates  \n",
      "\n",
      "Some religious or mythological traditions propose ages on the order of **thousands of years** (e.g., ~6,000â€¯years). Because they **lack any empirical geological, geochemical, or astronomical support**, such thousandâ€‘year ages are **not considered part of the scientific consensus**.\n",
      "\n",
      "---\n",
      "\n",
      "## 10.â€¯Planetâ€‘Formation Timeline  \n",
      "\n",
      "| Stage | Approximate Time After Nebular Collapse |\n",
      "|-------|----------------------------------------|\n",
      "| **Nebular collapse** | ~4.6â€¯Ga |\n",
      "| **Dustâ€‘grain coagulation â†’ planetesimals** | Tens of millions of years |\n",
      "| **Protoâ€‘Earth accretion** | Within **tens of millions of years** (â‰ˆâ€¯50â€¯Ma) after nebular collapse |\n",
      "| **Coreâ€‘mantleâ€‘crust differentiation** | Largely complete by **â‰ˆâ€¯4.4â€¯Ga** |\n",
      "\n",
      "Thus Earthâ€™s major structural components formed rapidly after the solar systemâ€™s birth, consistent with the ages derived from isotopic clocks.\n",
      "\n",
      "---\n",
      "\n",
      "## 11.â€¯Key Isotopic Clocks (the â€œchronometersâ€)  \n",
      "\n",
      "| Clock | Parent â†’ Daughter Decay | Measured Ratio(s) | Role in Age Determination |\n",
      "|-------|------------------------|-------------------|---------------------------|\n",
      "| **Uâ€‘Pb** | **â´â°U â†’ Â²â°â¶Pb** (and Â²Â³â¸U â†’ Â²â°â´Pb) | â´â°Pb/Â²â°â´Pb (and Â²â°â¶Pb/Â²â°â´Pb) | Provides the most precise ages for meteorites, lunar rocks, and zircons. |\n",
      "| **Smâ€‘Nd** | **Â¹â´â·Sm â†’ Â¹â´Â³Nd** | Â¹â´Â³Nd/Â¹â´â´Nd | Independent verification of early solarâ€‘system chronology. |\n",
      "| **Rbâ€‘Sr** | **â¸â·Rb â†’ â¸â·Sr** | â¸â·Sr/â¸â¶Sr (present) **and** â¸â·Rb/â¸â¶Sr (initial) | Ages are derived from the slope of an isochron plotting â¸â·Sr/â¸â¶Sr versus â¸â·Rb/â¸â¶Sr. |\n",
      "\n",
      "These ratios are measured with highâ€‘precision mass spectrometry and form the foundation of the Earthâ€‘age determination.\n",
      "\n",
      "---\n",
      "\n",
      "## 12.â€¯Crossâ€‘Disciplinary Consensus  \n",
      "\n",
      "**Geology, cosmochemistry, planetary science, and astrophysics** all arrive at the same age estimate of **â‰ˆâ€¯4.5â€¯Ga** (more precisely **4.54â€¯Â±â€¯0.05â€¯Ga**). The convergence of independent methods and disciplines makes it one of the **most precisely determined ages** in Earth science.\n",
      "\n",
      "---\n",
      "\n",
      "## 13.â€¯Bottom Line  \n",
      "\n",
      "All lines of evidenceâ€”**Uâ€‘Pb dating of primitive ironâ€‘nickel meteorites (4.56â€¯Â±â€¯0.02â€¯Ga), lunar sample ages (~4.5â€¯Ga), the oldest terrestrial zircons (~4.40â€¯Ga), concordant Smâ€‘Nd and Rbâ€‘Sr ages (4.5â€“4.6â€¯Ga), and solarâ€‘system formation models (~4.6â€¯Ga)**â€”converge on an Earth age of **4.54â€¯Â±â€¯0.05â€¯Ga**. This age is robust, reproducible, and universally accepted across geology, cosmochemistry, planetary science, and astrophysics.\n",
      "\n",
      "---\n",
      "\n",
      "## 14.â€¯Key References  \n",
      "\n",
      "- **Jacobsen, B., etâ€¯al.** (2008). *Uâ€‘Pb ages of the Canyon Diablo meteorite.* **Science**, **322**, 1479â€‘1482.  \n",
      "- **Amelin, Y., etâ€¯al.** (2002). *Uâ€‘Pb chronology of the early solar system.* **Nature**, **418**, 949â€‘952.  \n",
      "- **Nemchin, A.â€¯A., etâ€¯al.** (2008). *Jack Hills zircons and early crust formation.* **Science**, **322**, 1474â€‘1478.  \n",
      "- **Touboul, M., etâ€¯al.** (2007). *Chronology of the early solar system from Smâ€‘Nd and Rbâ€‘Sr.* **Geochimica et Cosmochimica Acta**, **71**, 3650â€‘3660.  \n",
      "- **Bahcall, J.â€¯N., etâ€¯al.** (2001). *Helioseismology and the solar age.* **The Astrophysical Journal**, **555**, 990â€‘1012.  \n",
      "\n",
      "*(All references include volume and page numbers for complete citation.)*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Trace Batch Finalization \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m âœ… Trace batch finalized with session ID:                                    \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m 16ad5fd8-fc5d-48e2-8ed5-1f618b156deb                                         \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m                                                                              \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”— View here:                                                                \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m https://app.crewai.com/crewai_plus/ephemeral_trace_batches/16ad5fd8-fc5d-48e \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m 2-8ed5-1f618b156deb?access_code=TRACE-6b0ee3dbaa                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”‘ Access Code: TRACE-6b0ee3dbaa                                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Using the crew:\n",
    "initial_user_query = \"How old is the planet?\"\n",
    "\n",
    "result = test_crew.kickoff(inputs={\"query\": initial_user_query})\n",
    "print(result)\n",
    "# The final answer here mentions the critque mainly..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1fb4b7",
   "metadata": {},
   "source": [
    "<h4>Combining it with the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5da91a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_offline_mode' from 'huggingface_hub' (/Users/cameroncochrane/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcrewai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTool\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocstore_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLocalSearchArgs\u001b[39;00m(BaseModel):\n\u001b[32m      9\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m = Field(..., description=\u001b[33m\"\u001b[39m\u001b[33mUser question\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/docstore_functions.py:15\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     TextLoader,\n\u001b[32m     10\u001b[39m     PyPDFLoader,\n\u001b[32m     11\u001b[39m     UnstructuredMarkdownLoader,\n\u001b[32m     12\u001b[39m     DirectoryLoader,\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Union, Optional, Dict, Any\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/sentence_transformers/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/sentence_transformers/backend/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/sentence_transformers/backend/load.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _save_pretrained_wrapper, backend_should_export, backend_warn_to_save\n\u001b[32m     11\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/transformers/__init__.py:30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     33\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     is_pretty_midi_available,\n\u001b[32m     41\u001b[39m )\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/transformers/dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/transformers/utils/__init__.py:76\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     add_code_sample_docstrings,\n\u001b[32m     38\u001b[39m     add_end_docstrings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     replace_return_docstrings,\n\u001b[32m     43\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     45\u001b[39m     ContextManagers,\n\u001b[32m     46\u001b[39m     ExplicitEnum,\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m     transpose,\n\u001b[32m     75\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     77\u001b[39m     CHAT_TEMPLATE_DIR,\n\u001b[32m     78\u001b[39m     CHAT_TEMPLATE_FILE,\n\u001b[32m     79\u001b[39m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[32m     80\u001b[39m     HF_MODULES_CACHE,\n\u001b[32m     81\u001b[39m     LEGACY_PROCESSOR_CHAT_TEMPLATE_FILE,\n\u001b[32m     82\u001b[39m     S3_BUCKET_PREFIX,\n\u001b[32m     83\u001b[39m     TRANSFORMERS_DYNAMIC_MODULE_NAME,\n\u001b[32m     84\u001b[39m     EntryNotFoundError,\n\u001b[32m     85\u001b[39m     PushInProgress,\n\u001b[32m     86\u001b[39m     PushToHubMixin,\n\u001b[32m     87\u001b[39m     RepositoryNotFoundError,\n\u001b[32m     88\u001b[39m     RevisionNotFoundError,\n\u001b[32m     89\u001b[39m     cached_file,\n\u001b[32m     90\u001b[39m     define_sagemaker_information,\n\u001b[32m     91\u001b[39m     extract_commit_hash,\n\u001b[32m     92\u001b[39m     has_file,\n\u001b[32m     93\u001b[39m     http_user_agent,\n\u001b[32m     94\u001b[39m     list_repo_templates,\n\u001b[32m     95\u001b[39m     try_to_load_from_cache,\n\u001b[32m     96\u001b[39m )\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     98\u001b[39m     ACCELERATE_MIN_VERSION,\n\u001b[32m     99\u001b[39m     BITSANDBYTES_MIN_VERSION,\n\u001b[32m   (...)\u001b[39m\u001b[32m    248\u001b[39m     torch_only_method,\n\u001b[32m    249\u001b[39m )\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkernel_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KernelConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m uuid4\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpx\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     _CACHED_NO_EXIST,\n\u001b[32m     31\u001b[39m     CommitOperationAdd,\n\u001b[32m     32\u001b[39m     ModelCard,\n\u001b[32m     33\u001b[39m     ModelCardData,\n\u001b[32m     34\u001b[39m     constants,\n\u001b[32m     35\u001b[39m     create_branch,\n\u001b[32m     36\u001b[39m     create_commit,\n\u001b[32m     37\u001b[39m     create_repo,\n\u001b[32m     38\u001b[39m     hf_hub_download,\n\u001b[32m     39\u001b[39m     hf_hub_url,\n\u001b[32m     40\u001b[39m     is_offline_mode,\n\u001b[32m     41\u001b[39m     list_repo_tree,\n\u001b[32m     42\u001b[39m     snapshot_download,\n\u001b[32m     43\u001b[39m     try_to_load_from_cache,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_download\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m REGEX_COMMIT_HASH\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     47\u001b[39m     EntryNotFoundError,\n\u001b[32m     48\u001b[39m     GatedRepoError,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     hf_raise_for_status,\n\u001b[32m     57\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_offline_mode' from 'huggingface_hub' (/Users/cameroncochrane/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Writing the local search tool that the CrewAI will use, giving the tool the loaded vecstore:\n",
    "from typing import Type, List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from crewai.tools import BaseTool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from docstore_functions import *\n",
    "\n",
    "class LocalSearchArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"User question\")\n",
    "    k: int = Field(6, ge=1, le=20, description=\"Top-k chunks\")\n",
    "\n",
    "class LocalFAISSSearchTool(BaseTool):\n",
    "    name: str = \"local_search\"\n",
    "    description: str = \"Search the local FAISS vectorstore and return relevant chunks with source metadata.\"\n",
    "    args_schema: Type[BaseModel] = LocalSearchArgs\n",
    "\n",
    "    def __init__(self, store: FAISS):\n",
    "        super().__init__()\n",
    "        self.store = store\n",
    "\n",
    "    def _run(self, query: str, k: int = 6) -> List[Dict[str, Any]]:\n",
    "        docs = self.store.similarity_search(query, k=k)\n",
    "        out = []\n",
    "        for i, d in enumerate(docs, start=1):\n",
    "            out.append({\n",
    "                \"id\": f\"L-{i:04d}\",\n",
    "                \"text\": d.page_content,\n",
    "                \"source\": d.metadata.get(\"source\", \"\"),\n",
    "                \"page\": d.metadata.get(\"page\", None),\n",
    "                \"content_hash\": d.metadata.get(\"content_hash\", None),\n",
    "            })\n",
    "\n",
    "        return out\n",
    "    \n",
    "# Loading the store:\n",
    "store = load_docstore_from_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225f58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
