{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3316f88a",
   "metadata": {},
   "source": [
    "<h2>Agentic RAG App: Groq LLM</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e56ab",
   "metadata": {},
   "source": [
    "<h3>LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c845f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cameroncochrane/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# LangChain has a Groq chat model integration:\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a03ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API groq API key:\n",
    "from pathlib import Path\n",
    "# Bespoke API key loader functions:\n",
    "from load_keys import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc9c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"keys/groq.json\")\n",
    "groq_api_key = load_groq_key(p)\n",
    "os.environ['GROQ_API_KEY'] = groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9814ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model:\n",
    "model = ChatGroq(\n",
    "            model=\"openai/gpt-oss-120b\",\n",
    "            temperature=0.2,\n",
    "            max_retries=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22262716",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = [(\"human\",\"hello, how are you?\")]\n",
    "answer_1 = model.invoke(initial_message) # .invoke to send a message to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a66c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing great, thank you for asking. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "extracted_message = answer_1.content # x.content returns the message for the user.\n",
    "print(extracted_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c939dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I donâ€™t have the ability to browse the web or pull in realâ€‘time information. My responses are based solely on the knowledge I was trained on, which goes up to Septemberâ€¯2021 (with a limited update through 2024). If you need the most current data, I recommend checking a reliable source directly.\n"
     ]
    }
   ],
   "source": [
    "internet_message = [(\"human\",\"Do you have internet access?\")]\n",
    "internet_answer = model.invoke(internet_message)\n",
    "print(internet_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945c233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm(model_type:str = 'openai/gpt-oss-120b',api_key_path:str = \"keys/groq.json\"):\n",
    "    \n",
    "    p = Path(api_key_path)\n",
    "\n",
    "    groq_api_key = load_groq_key(p)\n",
    "    os.environ['GROQ_API_KEY'] = groq_api_key\n",
    "    \n",
    "    model = ChatGroq(\n",
    "            model=model_type,\n",
    "            temperature=0.2,\n",
    "            max_retries=2,\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c705dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_message(model,message):\n",
    "\n",
    "    full_answer = model.invoke(message)\n",
    "    extracted_answer = full_answer.content\n",
    "\n",
    "    return extracted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e383e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Iâ€™m a versatile AI language model, and people use me for a wide variety of tasks across many domains. Here are some of the most common (and a few creative) use cases:\n",
      "\n",
      "---\n",
      "\n",
      "## 1. **Writing & Editing**\n",
      "| Task | How I help |\n",
      "|------|------------|\n",
      "| **Drafting emails, letters, or memos** | Generate professional or casual drafts, suggest subject lines, and polish tone. |\n",
      "| **Blog posts & articles** | Outline structures, write full drafts, add headings, SEO keywords, and citations. |\n",
      "| **Creative writing** | Produce short stories, poems, scripts, character bios, or plot twists. |\n",
      "| **Proofreading & grammar checks** | Spot typos, improve clarity, suggest style changes, and enforce house style guides. |\n",
      "| **Resume & cover letter** | Tailor content to specific job postings, highlight achievements, and format for ATS. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. **Learning & Tutoring**\n",
      "| Subject | What I can do |\n",
      "|---------|---------------|\n",
      "| **Academic subjects** (math, physics, chemistry, history, etc.) | Explain concepts, solve problems stepâ€‘byâ€‘step, generate practice questions. |\n",
      "| **Language learning** | Provide translations, grammar explanations, conversation practice, and vocabulary drills. |\n",
      "| **Test prep** | Create flashcards, practice quizzes, and strategies for exams like SAT, GRE, MCAT, etc. |\n",
      "| **Coding education** | Walk through algorithms, explain syntax, debug code, and suggest improvements. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. **Programming & Technical Assistance**\n",
      "| Area | Example uses |\n",
      "|------|--------------|\n",
      "| **Code generation** | Write functions, classes, or whole scripts in languages like Python, JavaScript, Java, C++, etc. |\n",
      "| **Debugging** | Identify errors, suggest fixes, and explain why a bug occurs. |\n",
      "| **Documentation** | Produce docstrings, API docs, README files, and changelogs. |\n",
      "| **Algorithm design** | Outline approaches, compare complexities, and provide pseudocode. |\n",
      "| **DevOps & cloud** | Explain CI/CD pipelines, write Dockerfiles, Terraform configs, or AWS CLI commands. |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. **Research & Information Synthesis**\n",
      "| Need | How I assist |\n",
      "|------|--------------|\n",
      "| **Literature reviews** | Summarize papers, compare findings, and generate citation lists (in APA, MLA, Chicago, etc.). |\n",
      "| **Market research** | Outline industry trends, competitor analysis, and SWOT frameworks. |\n",
      "| **Data interpretation** | Explain statistical results, suggest visualizations, and write insights. |\n",
      "| **Factâ€‘checking** | Provide quick verification of claims (with a disclaimer to doubleâ€‘check sources). |\n",
      "| **Summarization** | Condense long articles, reports, or meeting minutes into concise bullet points. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. **Productivity & Organization**\n",
      "| Scenario | What I can do |\n",
      "|----------|---------------|\n",
      "| **Toâ€‘do lists & task planning** | Break down projects into actionable steps, prioritize using Eisenhower matrix, set deadlines. |\n",
      "| **Meeting agendas & minutes** | Draft agendas, capture key points, and generate followâ€‘up action items. |\n",
      "| **Calendar management** | Suggest optimal scheduling patterns, timeâ€‘blocking strategies, and reminders. |\n",
      "| **Brainstorming** | Generate ideas for product features, marketing campaigns, names, slogans, etc. |\n",
      "| **Decision analysis** | Create pros/cons tables, decision trees, or costâ€‘benefit analyses. |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. **Customer Support & Interaction**\n",
      "| Application | How I help |\n",
      "|-------------|------------|\n",
      "| **Chatbot scripts** | Write conversational flows, FAQs, and escalation guidelines. |\n",
      "| **Ticket triage** | Summarize user issues, suggest categories, and draft response templates. |\n",
      "| **Product documentation** | Create user guides, troubleshooting steps, and knowledgeâ€‘base articles. |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. **Creative & Entertainment Projects**\n",
      "| Project | My role |\n",
      "|---------|---------|\n",
      "| **Game design** | Conceptualize mechanics, write lore, design quests, and balance systems. |\n",
      "| **Music & lyrics** | Generate lyric ideas, suggest chord progressions, or write short song verses. |\n",
      "| **Visual art prompts** | Provide detailed prompts for AI image generators (e.g., DALLÂ·E, Stable Diffusion). |\n",
      "| **Roleâ€‘playing** | Act as a DM/NPC, create scenarios, and improvise dialogue. |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. **Personal Development & Wellâ€‘Being**\n",
      "| Goal | How I can assist |\n",
      "|------|-------------------|\n",
      "| **Goal setting** | Define SMART goals, break them into milestones, and track progress. |\n",
      "| **Mindfulness & journaling** | Offer guided meditation scripts, journal prompts, or reflective questions. |\n",
      "| **Fitness & nutrition** | Suggest workout routines, meal plans (with a disclaimer to consult professionals). |\n",
      "| **Career coaching** | Provide interview practice, salary negotiation tips, and skillâ€‘gap analysis. |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. **Legal & Business Drafting (Nonâ€‘Advice)**\n",
      "| Document | What I can produce |\n",
      "|----------|--------------------|\n",
      "| **Contracts & agreements** | Template clauses, simple NDAs, service agreements (always review with a qualified attorney). |\n",
      "| **Business plans** | Executive summary, market analysis, financial projections outline. |\n",
      "| **Policy documents** | HR policies, privacy statements, terms of service drafts. |\n",
      "\n",
      "---\n",
      "\n",
      "## 10. **Fun & Miscellaneous**\n",
      "- **Trivia & quizzes**: Generate random trivia questions or themed quizzes.\n",
      "- **Horoscopes & personality tests**: Write playful horoscopes or fun MBTIâ€‘style descriptions.\n",
      "- **Cooking**: Suggest recipes based on ingredients, dietary restrictions, or cuisine preferences.\n",
      "- **Travel planning**: Create itineraries, recommend attractions, and list packing essentials.\n",
      "\n",
      "---\n",
      "\n",
      "### How to Get the Most Out of Me\n",
      "1. **Be specific** â€“ The clearer your prompt, the more targeted the output.  \n",
      "   *Example*: â€œWrite a 300â€‘word blog intro about renewable energy for a techâ€‘savvy audienceâ€ vs. â€œWrite about renewable energy.â€\n",
      "2. **Iterate** â€“ Ask followâ€‘up questions, request revisions, or ask for alternative versions.  \n",
      "3. **Provide context** â€“ Share any relevant background (tone, audience, format) up front.  \n",
      "4. **Set constraints** â€“ Mention word limits, style guides, or required sections early on.\n",
      "\n",
      "---\n",
      "\n",
      "If you have a particular project or problem in mind, just let me know and I can dive deeper into how I could help!\n"
     ]
    }
   ],
   "source": [
    "model_1 = load_llm()\n",
    "extracted_answer = give_message(model_1,\"What are some of your use cases?\")\n",
    "print(extracted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7396097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have the basic llm functionality sorted. Can move onto adding agents with CrewAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df8be7",
   "metadata": {},
   "source": [
    "<h4>CrewAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea52df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from load_keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04101b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key_path = Path('keys/open_ai.json')\n",
    "openai_key = load_openai_key(openai_key_path)\n",
    "os.environ['OPENAI_API_KEY'] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78f04826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crew(llm):\n",
    "    researcher = Agent(\n",
    "        role=\"Researcher\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Retrieve and compile evidence using the provided LLM as the sole knowledge source (do NOT call external/local tools).\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    writer = Agent(\n",
    "        role=\"Content Writer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Write a structured answer grounded in the evidence produced by the Researcher (LLM).\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    critic = Agent(\n",
    "        role=\"Reviewer\",\n",
    "        backstory=\"\",\n",
    "        goal=\"Check the answer for unsupported claims, missing info, and clarity against the Researcher's evidence.\",\n",
    "        llm=llm,\n",
    "        tools=[],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    t1 = Task(\n",
    "        description=(\n",
    "            \"Research the user's query using only the LLM as the knowledge base. Return a bullet list of findings.\"\n",
    "        ),\n",
    "        expected_output=\"A bullet list of findings derived from the LLM only.\",\n",
    "        agent=researcher,\n",
    "    )\n",
    "\n",
    "    t2 = Task(\n",
    "        description=(\n",
    "            \"Write the final answer in Markdown. Use the Researcher's findings as the source.\"\n",
    "        ),\n",
    "        expected_output=\"A Markdown response mapped to the Researcher's findings.\",\n",
    "        agent=writer,\n",
    "        context=[t1],\n",
    "    )\n",
    "\n",
    "    t3 = Task(\n",
    "        description=(\n",
    "            \"Critique the answer against the Researcher's response. List issues and provide fix instructions.\"\n",
    "        ),\n",
    "        expected_output=\"A list of issues found plus concrete fix instructions.\",\n",
    "        agent=critic,\n",
    "        context=[t1, t2],\n",
    "    )\n",
    "\n",
    "    return Crew(\n",
    "        agents=[researcher, writer, critic],\n",
    "        tasks=[t1, t2, t3],\n",
    "        process=Process.sequential,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "llm_for_crew = LLM(\n",
    "    model=\"groq/openai/gpt-oss-120b\",\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "crew = build_crew(llm=llm_for_crew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af7b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Issues Identified**\n",
      "\n",
      "1. **Missing Request for Constraints**  \n",
      "   - The Researcherâ€™s prompt explicitly asks for â€œany particular focus areas, subâ€‘questions, or constraints.â€ The answer does not request this information, leaving a potential gap in the userâ€™s specifications.\n",
      "\n",
      "2. **No Mention of Output Format**  \n",
      "   - The Researcher states that the findings will be delivered as a â€œbulletâ€‘point list.â€ The answer fails to confirm that this is the intended format, which could lead to a mismatch in expectations.\n",
      "\n",
      "3. **Lack of Confirmation About Source Limitation**  \n",
      "   - The Researcher specifies that the findings will be compiled â€œusing the language model as the sole source.â€ The answer does not acknowledge or repeat this limitation, which is a key part of the request.\n",
      "\n",
      "4. **Redundant or Overly Formal Language**  \n",
      "   - The answer repeats the same request verbatim without adding any clarification or friendly framing. This can feel robotic and may reduce user engagement.\n",
      "\n",
      "5. **No Assurance of Followâ€‘Up**  \n",
      "   - The answer does not reassure the user that once the details are provided, the assistant will promptly generate the requested bulletâ€‘point list. This omission may leave the user uncertain about the next steps.\n",
      "\n",
      "---\n",
      "\n",
      "**Fix Instructions**\n",
      "\n",
      "1. **Add a Prompt for Constraints**  \n",
      "   - Include a line such as: â€œPlease also let me know if you have any specific constraints (e.g., word limit, date range, perspective) that I should keep in mind.â€\n",
      "\n",
      "2. **State the Intended Output Format**  \n",
      "   - Clearly mention that the findings will be presented as a bulletâ€‘point list, e.g., â€œI will compile the findings into a concise bulletâ€‘point list for easy reference.â€\n",
      "\n",
      "3. **Reâ€‘affirm the Source Limitation**  \n",
      "   - Add a sentence confirming that the research will rely solely on the language model, e.g., â€œAll information will be generated using the language model as the sole source, without external references.â€\n",
      "\n",
      "4. **Make the Request More Conversational**  \n",
      "   - Slightly reâ€‘phrase the request to sound friendly and engaging, for example: â€œIâ€™m happy to help! Could you let me knowâ€¦?â€\n",
      "\n",
      "5. **Provide a Clear Nextâ€‘Step Assurance**  \n",
      "   - End with a brief assurance, such as: â€œOnce I have those details, Iâ€™ll get right to work and send you the bulletâ€‘point summary.â€\n",
      "\n",
      "---\n",
      "\n",
      "**Revised Answer Example (to be used as a template)**\n",
      "\n",
      "> Iâ€™m happy to help! Could you please let me know:\n",
      "> \n",
      "> - The specific topic or question youâ€™d like investigated.  \n",
      "> - Any particular focus areas, subâ€‘questions, or constraints (e.g., word limit, date range, perspective).  \n",
      "> \n",
      "> Once I have those details, Iâ€™ll compile the findings into a concise bulletâ€‘point list, using the language model as the sole source. Looking forward to your clarification so I can get started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Trace Batch Finalization \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m âœ… Trace batch finalized with session ID:                                    \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m 8dd14c6e-7634-4a6c-a92e-9c9efdc01171                                         \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m                                                                              \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”— View here:                                                                \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m https://app.crewai.com/crewai_plus/ephemeral_trace_batches/8dd14c6e-7634-4a6 \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m c-a92e-9c9efdc01171?access_code=TRACE-08ccacbb8c                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ”‚\u001b[0m ğŸ”‘ Access Code: TRACE-08ccacbb8c                                             \u001b[32mâ”‚\u001b[0m\n",
      "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Using the crew:\n",
    "user_query = \"How old is the planet?\"\n",
    "\n",
    "result = crew.kickoff(inputs={\"query\": user_query})\n",
    "print(result)\n",
    "# The critic and writer agents are working. It doesn't appear to be the same for the researcher agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416d96a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
