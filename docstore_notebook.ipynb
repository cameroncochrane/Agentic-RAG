{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fb9685",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<h2>Agentic RAG App Doc-store (Vector-store) and Embeddings</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891872f1",
   "metadata": {},
   "source": [
    "Will get a doc/vector store established, and play around with it to see how it works with the groq LLM. Any missing information will then be filled by implementing with tavily (internet-search). Will then establish agents with specific roles with CrewAI. Write functions for this (week 1), and then establish the streamlit front-end (week 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739319b1",
   "metadata": {},
   "source": [
    "<h3>Doc-store (Vector-store) and Embeddings</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b0a1e0",
   "metadata": {},
   "source": [
    "1. Your documents live locally in your project\n",
    "\n",
    "2. You turn those documents into embeddings (numbers)\n",
    "\n",
    "3. You store those numbers locally in FAISS\n",
    "\n",
    "4. A user asks a question. The question is directed to the 'researcher' agent of CrewAI.\n",
    "\n",
    "5. The researcher finds the most relevant document chunks using FAISS, or use 'tavily' to do an internet search for the information.\n",
    "\n",
    "6. You send those chunks to Groq. The other agents use grow to fulfill their role.\n",
    "\n",
    "7. Groq writes the answer\n",
    "\n",
    "Groq never sees embeddings.\n",
    "FAISS never talks to Groq.\n",
    "The agents of CrewAI are agents, they use groq in different ways to fulfill their role e.g find an answer, write and answer, critique an answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba59ab",
   "metadata": {},
   "source": [
    "<h4>Creating the doc store (done using FAISS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574b1a9",
   "metadata": {},
   "source": [
    "We need to create a vector-store that can take in docuements and store them. We need to be able to save the store so we don't have to keep feeding it the same doceuments between uses. We also wnat to be able to add new docuemnts as we find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ce3332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cameroncochrane/Data Projects/Agentic-RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import langchain_core\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    DirectoryLoader,\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a2e7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_directory(directory_path: str):\n",
    "    \"\"\"\n",
    "    Scan a given directory and return the paths of all files inside.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path of the directory to scan.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of file paths.\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f25a4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Union, Optional\n",
    "from __future__ import annotations\n",
    "import hashlib\n",
    "\n",
    "# wrapper around sentence_transformers to match LangChain embeddings interface\n",
    "class SentenceTransformerEmbeddingsWrapper:\n",
    "    def __init__(self, model_name: str = \"BAAI/bge-small-en-v1.5\", lazy: bool = True):\n",
    "        # lazy=True avoids downloading the model at import/definition time.\n",
    "        self.model_name = model_name\n",
    "        self._model: Optional[SentenceTransformer] = None\n",
    "        self.lazy = lazy\n",
    "        if not self.lazy:\n",
    "            self._ensure_model()\n",
    "\n",
    "    def _ensure_model(self) -> None:\n",
    "        if self._model is None:\n",
    "            self._model = SentenceTransformer(self.model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Return embeddings for a list of documents.\n",
    "        This matches LangChain's `embed_documents` contract.\n",
    "        \"\"\"\n",
    "        self._ensure_model()\n",
    "        emb = self._model.encode(texts, show_progress_bar=False)\n",
    "        return emb.tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        self._ensure_model()\n",
    "        emb = self._model.encode([text], show_progress_bar=False)\n",
    "        return emb[0].tolist()\n",
    "\n",
    "    def __call__(self, texts: Union[str, List[str]]):\n",
    "        # Support both single-query strings and lists of documents.\n",
    "        if isinstance(texts, str):\n",
    "            return self.embed_query(texts)\n",
    "        if isinstance(texts, (list, tuple)):\n",
    "            return self.embed_documents(list(texts))\n",
    "        raise TypeError(f\"Unsupported input type for embeddings: {type(texts)}\")\n",
    "    \n",
    "def create_faiss_store_from_documents(documents: List[Document], index_dir: str = \"vectorstore\", embedding_model: str = \"BAAI/bge-small-en-v1.5\"):\n",
    "    \"\"\"\n",
    "    Build a FAISS vectorstore from a list of langchain Document objects and save it to disk.\n",
    "    Returns the in-memory FAISS store.\n",
    "    \"\"\"\n",
    "    os.makedirs(index_dir, exist_ok=True)\n",
    "    embeddings = SentenceTransformerEmbeddingsWrapper(embedding_model)\n",
    "    # Pass the embeddings wrapper object so FAISS can access its\n",
    "    # `embed_documents` / `embed_query` methods as expected.\n",
    "    store = FAISS.from_documents(documents, embeddings)\n",
    "    store.save_local(index_dir)\n",
    "    return store\n",
    "\n",
    "def load_faiss_store(index_dir: str = \"vectorstore\", embedding_model: str = \"all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Load a previously saved FAISS vectorstore from disk.\n",
    "    \"\"\"\n",
    "    embeddings = SentenceTransformerEmbeddingsWrapper(embedding_model)\n",
    "    # FAISS.load_local expects an embeddings object providing `embed_documents`\n",
    "    return FAISS.load_local(index_dir, embeddings)\n",
    "\n",
    "def add_documents_and_save(store: FAISS, new_documents: List[Document], index_dir: str = \"vectorstore\"):\n",
    "    \"\"\"\n",
    "    Add documents to an existing FAISS store and persist to disk.\n",
    "    \"\"\"\n",
    "    store.add_documents(new_documents)\n",
    "    store.save_local(index_dir)\n",
    "    return store\n",
    "\n",
    "\n",
    "def path_upload_document_to_vectorstore(\n",
    "    document_paths: Union[str, List[str]],\n",
    "    store: FAISS,\n",
    "    index_dir: str = \"vectorstore\",\n",
    "    dedup_mode: str = \"content\",  # \"content\" (recommended) or \"source\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload one or more documents to an existing FAISS vectorstore and persist to disk\n",
    "    Ensures each Document has a `content_hash` in metadata so subsequent\n",
    "    content-based deduplication works even for the initial ingestion.\n",
    "    WITHOUT erasing existing contents, with deduplication.\n",
    "\n",
    "    # Ensure documents have a content_hash for idempotent ingestion\n",
    "    def _content_hash(text: str) -> str:\n",
    "        return hashlib.sha256((text or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    for d in documents:\n",
    "        # only operate on Document instances\n",
    "        if not isinstance(d, Document):\n",
    "            continue\n",
    "        h = d.metadata.get(\"content_hash\")\n",
    "        if not h:\n",
    "            h = _content_hash(d.page_content)\n",
    "            d.metadata[\"content_hash\"] = h\n",
    "        # ensure a source field exists for traceability\n",
    "        d.metadata.setdefault(\"source\", d.metadata.get(\"source\", \"\"))\n",
    "    Deduplication behavior:\n",
    "      - dedup_mode=\"content\": hashes each loaded Document.page_content and skips exact duplicates.\n",
    "      - dedup_mode=\"source\": skips if an existing Document has the same metadata[\"source\"].\n",
    "\n",
    "    Notes:\n",
    "      - For PDFs, PyPDFLoader returns one Document per page; dedup will happen at page level.\n",
    "      - This function assumes your loaders populate metadata[\"source\"] (LangChain usually does).\n",
    "    \"\"\"\n",
    "    if isinstance(document_paths, str):\n",
    "        document_paths = [document_paths]\n",
    "    \n",
    "    def _content_hash(text: str) -> str:\n",
    "        # stable content-based id\n",
    "        return hashlib.sha256((text or \"\").encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "    def _get_existing_hashes(store: FAISS) -> set[str]:\n",
    "        \"\"\"\n",
    "        Extract content hashes from the existing LangChain FAISS docstore.\n",
    "        We store hashes in Document.metadata[\"content_hash\"] for idempotent ingestion.\n",
    "        \"\"\"\n",
    "        existing = set()\n",
    "\n",
    "        # LangChain FAISS keeps docs in an InMemoryDocstore at store.docstore._dict\n",
    "        doc_dict = getattr(getattr(store, \"docstore\", None), \"_dict\", None)\n",
    "        if isinstance(doc_dict, dict):\n",
    "            for d in doc_dict.values():\n",
    "                if isinstance(d, Document):\n",
    "                    h = d.metadata.get(\"content_hash\")\n",
    "                    if h:\n",
    "                        existing.add(h)\n",
    "        return existing\n",
    "\n",
    "    # Build the dedup index from the current store\n",
    "    existing_hashes = _get_existing_hashes(store) if dedup_mode == \"content\" else set()\n",
    "\n",
    "    existing_sources = set()\n",
    "    if dedup_mode == \"source\":\n",
    "        doc_dict = getattr(getattr(store, \"docstore\", None), \"_dict\", None)\n",
    "        if isinstance(doc_dict, dict):\n",
    "            for d in doc_dict.values():\n",
    "                if isinstance(d, Document):\n",
    "                    src = d.metadata.get(\"source\")\n",
    "                    if src:\n",
    "                        existing_sources.add(src)\n",
    "\n",
    "    total_added = 0\n",
    "    total_skipped = 0\n",
    "\n",
    "    for document_path in document_paths:\n",
    "        # Determine the loader type based on file extension\n",
    "        if document_path.lower().endswith(\".pdf\"):\n",
    "            loader_cls = PyPDFLoader\n",
    "        elif document_path.lower().endswith(\".txt\"):\n",
    "            loader_cls = TextLoader\n",
    "        elif document_path.lower().endswith(\".md\"):\n",
    "            loader_cls = UnstructuredMarkdownLoader\n",
    "        else:\n",
    "            print(f\"Unsupported file type for {document_path}. Supported types are: .pdf, .txt, .md\")\n",
    "            continue\n",
    "\n",
    "        # Load the document(s)\n",
    "        try:\n",
    "            loader = loader_cls(document_path)\n",
    "            loaded_docs = loader.load()\n",
    "            print(f\"Loaded {len(loaded_docs)} document(s) from {document_path}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading document {document_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Tag documents with dedup metadata and filter duplicates\n",
    "        new_docs: List[Document] = []\n",
    "        for d in loaded_docs:\n",
    "            # Ensure source is set for traceability (helps source-based dedup & citations)\n",
    "            d.metadata.setdefault(\"source\", document_path)\n",
    "\n",
    "            if dedup_mode == \"source\":\n",
    "                src = d.metadata.get(\"source\")\n",
    "                if src in existing_sources:\n",
    "                    total_skipped += 1\n",
    "                    continue\n",
    "                existing_sources.add(src)\n",
    "                new_docs.append(d)\n",
    "                continue\n",
    "\n",
    "            # content-based dedup (recommended)\n",
    "            h = d.metadata.get(\"content_hash\")\n",
    "            if not h:\n",
    "                h = _content_hash(d.page_content)\n",
    "                d.metadata[\"content_hash\"] = h\n",
    "\n",
    "            if h in existing_hashes:\n",
    "                total_skipped += 1\n",
    "                continue\n",
    "\n",
    "            existing_hashes.add(h)\n",
    "            new_docs.append(d)\n",
    "\n",
    "        if not new_docs:\n",
    "            print(f\"No new chunks/pages to add from {document_path} (all duplicates).\")\n",
    "            continue\n",
    "\n",
    "        # Add to store and persist\n",
    "        store.add_documents(new_docs)\n",
    "        store.save_local(index_dir)\n",
    "        total_added += len(new_docs)\n",
    "\n",
    "        print(f\"Added {len(new_docs)} new document(s) from {document_path} and saved to '{index_dir}'.\")\n",
    "\n",
    "    print(f\"Done. Added: {total_added}, skipped as duplicates: {total_skipped}.\")\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a84bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 2507.41it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-small-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# load the initial document (init_document.pdf)\n",
    "run = False\n",
    "if run == True:\n",
    "    initial_document_directory = \"initial_document\" # When first creating the store, use a test document. Next, when adding more documents, use the path_upload_document_to_vectorstore() function with the main documents in 'documents' folder\n",
    "    loader = DirectoryLoader(initial_document_directory)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Create a FAISS vector store from the loaded documents\n",
    "    store = create_faiss_store_from_documents(docs, index_dir=\"vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07d67ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 document(s) from documents/c1cs15013h.pdf.\n",
      "Added 15 new document(s) from documents/c1cs15013h.pdf and saved to 'vectorstore'.\n",
      "Loaded 13 document(s) from documents/c5cs00105f.pdf.\n",
      "Added 13 new document(s) from documents/c5cs00105f.pdf and saved to 'vectorstore'.\n",
      "Loaded 65 document(s) from documents/photochemical-approaches-to-complex-chemotypes-applications-in-natural-product-synthesis.pdf.\n",
      "Added 65 new document(s) from documents/photochemical-approaches-to-complex-chemotypes-applications-in-natural-product-synthesis.pdf and saved to 'vectorstore'.\n",
      "Loaded 17 document(s) from documents/c9np00039a.pdf.\n",
      "Added 17 new document(s) from documents/c9np00039a.pdf and saved to 'vectorstore'.\n",
      "Loaded 42 document(s) from documents/c5ob00169b.pdf.\n",
      "Added 42 new document(s) from documents/c5ob00169b.pdf and saved to 'vectorstore'.\n",
      "Loaded 7 document(s) from documents/d2qo00043a.pdf.\n",
      "Added 7 new document(s) from documents/d2qo00043a.pdf and saved to 'vectorstore'.\n",
      "Loaded 48 document(s) from documents/natural-product-synthesis-using-multicomponent-reaction-strategies.pdf.\n",
      "Added 48 new document(s) from documents/natural-product-synthesis-using-multicomponent-reaction-strategies.pdf and saved to 'vectorstore'.\n",
      "Loaded 19 document(s) from documents/Angew Chem Int Ed - 2009 - Kumar - Synthesis of Natural Product Inspired Compound Collections.pdf.\n",
      "Added 19 new document(s) from documents/Angew Chem Int Ed - 2009 - Kumar - Synthesis of Natural Product Inspired Compound Collections.pdf and saved to 'vectorstore'.\n",
      "Loaded 15 document(s) from documents/c3np70090a.pdf.\n",
      "Added 15 new document(s) from documents/c3np70090a.pdf and saved to 'vectorstore'.\n",
      "Loaded 24 document(s) from documents/Recent progress in the total synthesis of pyrrolecontaining natural products.pdf.\n",
      "Added 24 new document(s) from documents/Recent progress in the total synthesis of pyrrolecontaining natural products.pdf and saved to 'vectorstore'.\n",
      "Loaded 19 document(s) from documents/c5np00046g.pdf.\n",
      "Added 19 new document(s) from documents/c5np00046g.pdf and saved to 'vectorstore'.\n",
      "Loaded 12 document(s) from documents/b901245c.pdf.\n",
      "Added 12 new document(s) from documents/b901245c.pdf and saved to 'vectorstore'.\n",
      "Loaded 34 document(s) from documents/semipinacol-rearrangement-in-natural-product-synthesis.pdf.\n",
      "Added 34 new document(s) from documents/semipinacol-rearrangement-in-natural-product-synthesis.pdf and saved to 'vectorstore'.\n",
      "Loaded 43 document(s) from documents/c8cs00716k.pdf.\n",
      "Added 43 new document(s) from documents/c8cs00716k.pdf and saved to 'vectorstore'.\n",
      "Loaded 39 document(s) from documents/Angew Chem Int Ed - 2016 - Chung - Stereoselective Halogenation in Natural Product Synthesis.pdf.\n",
      "Added 39 new document(s) from documents/Angew Chem Int Ed - 2016 - Chung - Stereoselective Halogenation in Natural Product Synthesis.pdf and saved to 'vectorstore'.\n",
      "Loaded 50 document(s) from documents/radical-reactions-in-natural-product-synthesis.pdf.\n",
      "Added 50 new document(s) from documents/radical-reactions-in-natural-product-synthesis.pdf and saved to 'vectorstore'.\n",
      "Loaded 19 document(s) from documents/Liebigs Annalen - June 23  1997 - Nicolaou - The Wittig and Related Reactions in Natural Product Synthesis.pdf.\n",
      "Added 19 new document(s) from documents/Liebigs Annalen - June 23  1997 - Nicolaou - The Wittig and Related Reactions in Natural Product Synthesis.pdf and saved to 'vectorstore'.\n",
      "Loaded 29 document(s) from documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf.\n",
      "Added 29 new document(s) from documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf and saved to 'vectorstore'.\n",
      "Loaded 11 document(s) from documents/c3qo00086a.pdf.\n",
      "Added 11 new document(s) from documents/c3qo00086a.pdf and saved to 'vectorstore'.\n",
      "Loaded 16 document(s) from documents/c8cs00379c.pdf.\n",
      "Added 16 new document(s) from documents/c8cs00379c.pdf and saved to 'vectorstore'.\n",
      "Loaded 11 document(s) from documents/b816703f.pdf.\n",
      "Added 11 new document(s) from documents/b816703f.pdf and saved to 'vectorstore'.\n",
      "Done. Added: 548, skipped as duplicates: 0.\n"
     ]
    }
   ],
   "source": [
    "# Update FAISS store with all files under `directory_path` (documents/) (These are the main and bulk of the vestorstore)\n",
    "main_documents_directory = \"documents\"\n",
    "file_paths = scan_directory(main_documents_directory)\n",
    "store = path_upload_document_to_vectorstore(file_paths, store, index_dir=\"vectorstore\", dedup_mode=\"content\")\n",
    "# Note: this notebook now computes and persists metadata['content_hash'] at initial ingestion.\n",
    "# New indexes created after this change will include content hashes and enable immediate\n",
    "# content-based deduplication. If you have an older index created before this change,\n",
    "# rebuild it or run the upload path to add hashes before relying on content deduplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 document(s) from documents/c1cs15013h.pdf.\n",
      "No new chunks/pages to add from documents/c1cs15013h.pdf (all duplicates).\n",
      "Loaded 13 document(s) from documents/c5cs00105f.pdf.\n",
      "No new chunks/pages to add from documents/c5cs00105f.pdf (all duplicates).\n",
      "Loaded 65 document(s) from documents/photochemical-approaches-to-complex-chemotypes-applications-in-natural-product-synthesis.pdf.\n",
      "No new chunks/pages to add from documents/photochemical-approaches-to-complex-chemotypes-applications-in-natural-product-synthesis.pdf (all duplicates).\n",
      "Loaded 17 document(s) from documents/c9np00039a.pdf.\n",
      "No new chunks/pages to add from documents/c9np00039a.pdf (all duplicates).\n",
      "Loaded 42 document(s) from documents/c5ob00169b.pdf.\n",
      "No new chunks/pages to add from documents/c5ob00169b.pdf (all duplicates).\n",
      "Loaded 7 document(s) from documents/d2qo00043a.pdf.\n",
      "No new chunks/pages to add from documents/d2qo00043a.pdf (all duplicates).\n",
      "Loaded 48 document(s) from documents/natural-product-synthesis-using-multicomponent-reaction-strategies.pdf.\n",
      "No new chunks/pages to add from documents/natural-product-synthesis-using-multicomponent-reaction-strategies.pdf (all duplicates).\n",
      "Loaded 19 document(s) from documents/Angew Chem Int Ed - 2009 - Kumar - Synthesis of Natural Product Inspired Compound Collections.pdf.\n",
      "No new chunks/pages to add from documents/Angew Chem Int Ed - 2009 - Kumar - Synthesis of Natural Product Inspired Compound Collections.pdf (all duplicates).\n",
      "Loaded 15 document(s) from documents/c3np70090a.pdf.\n",
      "No new chunks/pages to add from documents/c3np70090a.pdf (all duplicates).\n",
      "Loaded 24 document(s) from documents/Recent progress in the total synthesis of pyrrolecontaining natural products.pdf.\n",
      "No new chunks/pages to add from documents/Recent progress in the total synthesis of pyrrolecontaining natural products.pdf (all duplicates).\n",
      "Loaded 19 document(s) from documents/c5np00046g.pdf.\n",
      "No new chunks/pages to add from documents/c5np00046g.pdf (all duplicates).\n",
      "Loaded 12 document(s) from documents/b901245c.pdf.\n",
      "No new chunks/pages to add from documents/b901245c.pdf (all duplicates).\n",
      "Loaded 34 document(s) from documents/semipinacol-rearrangement-in-natural-product-synthesis.pdf.\n",
      "No new chunks/pages to add from documents/semipinacol-rearrangement-in-natural-product-synthesis.pdf (all duplicates).\n",
      "Loaded 43 document(s) from documents/c8cs00716k.pdf.\n",
      "No new chunks/pages to add from documents/c8cs00716k.pdf (all duplicates).\n",
      "Loaded 39 document(s) from documents/Angew Chem Int Ed - 2016 - Chung - Stereoselective Halogenation in Natural Product Synthesis.pdf.\n",
      "No new chunks/pages to add from documents/Angew Chem Int Ed - 2016 - Chung - Stereoselective Halogenation in Natural Product Synthesis.pdf (all duplicates).\n",
      "Loaded 50 document(s) from documents/radical-reactions-in-natural-product-synthesis.pdf.\n",
      "No new chunks/pages to add from documents/radical-reactions-in-natural-product-synthesis.pdf (all duplicates).\n",
      "Loaded 19 document(s) from documents/Liebigs Annalen - June 23  1997 - Nicolaou - The Wittig and Related Reactions in Natural Product Synthesis.pdf.\n",
      "No new chunks/pages to add from documents/Liebigs Annalen - June 23  1997 - Nicolaou - The Wittig and Related Reactions in Natural Product Synthesis.pdf (all duplicates).\n",
      "Loaded 29 document(s) from documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf.\n",
      "No new chunks/pages to add from documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf (all duplicates).\n",
      "Loaded 11 document(s) from documents/c3qo00086a.pdf.\n",
      "No new chunks/pages to add from documents/c3qo00086a.pdf (all duplicates).\n",
      "Loaded 16 document(s) from documents/c8cs00379c.pdf.\n",
      "No new chunks/pages to add from documents/c8cs00379c.pdf (all duplicates).\n",
      "Loaded 11 document(s) from documents/b816703f.pdf.\n",
      "No new chunks/pages to add from documents/b816703f.pdf (all duplicates).\n",
      "Done. Added: 0, skipped as duplicates: 548.\n"
     ]
    }
   ],
   "source": [
    "# Re-run to test it's duplicate spotting capabilities\n",
    "main_documents_directory = \"documents\"\n",
    "file_paths = scan_directory(main_documents_directory)\n",
    "store = path_upload_document_to_vectorstore(file_paths, store, index_dir=\"vectorstore\", dedup_mode=\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd371906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working nicely!! It spots duplicates!\n",
    "\n",
    "# Can we import a docstore for use betweem sessions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34c2ee70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FAISS store from 'vectorstore' with 549 document(s).\n"
     ]
    }
   ],
   "source": [
    "def load_docstore_from_dir(index_dir: str = \"vectorstore\", embedding_model: str = \"BAAI/bge-small-en-v1.5\"):\n",
    "    \"\"\"\n",
    "    Load a FAISS-backed docstore from disk and return (store, documents_list).\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(index_dir):\n",
    "        raise FileNotFoundError(f\"Index directory '{index_dir}' not found.\")\n",
    "\n",
    "    embeddings = SentenceTransformerEmbeddingsWrapper(embedding_model)\n",
    "    try:\n",
    "        store = FAISS.load_local(index_dir, embeddings, allow_dangerous_deserialization=True)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load FAISS store from '{index_dir}': {e}\")\n",
    "\n",
    "    doc_dict = getattr(getattr(store, \"docstore\", None), \"_dict\", None) or {}\n",
    "    docs = [d for d in doc_dict.values() if isinstance(d, Document)]\n",
    "\n",
    "    print(f\"Loaded FAISS store from '{index_dir}' with {len(docs)} document(s).\")\n",
    "    return store, docs\n",
    "\n",
    "loaded_vstore, laoded_vstore_docs = load_docstore_from_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88f8aa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 document(s) from documents/c1cs15013h.pdf.\n",
      "No new chunks/pages to add from documents/c1cs15013h.pdf (all duplicates).\n",
      "Loaded 13 document(s) from documents/c5cs00105f.pdf.\n",
      "No new chunks/pages to add from documents/c5cs00105f.pdf (all duplicates).\n",
      "Loaded 65 document(s) from documents/photochemical-approaches-to-complex-chemotypes-applications-in-natural-product-synthesis.pdf.\n",
      "No new chunks/pages to add from documents/photochemical-approaches-to-complex-chemotypes-applications-in-natural-product-synthesis.pdf (all duplicates).\n",
      "Loaded 17 document(s) from documents/c9np00039a.pdf.\n",
      "No new chunks/pages to add from documents/c9np00039a.pdf (all duplicates).\n",
      "Loaded 42 document(s) from documents/c5ob00169b.pdf.\n",
      "No new chunks/pages to add from documents/c5ob00169b.pdf (all duplicates).\n",
      "Loaded 7 document(s) from documents/d2qo00043a.pdf.\n",
      "No new chunks/pages to add from documents/d2qo00043a.pdf (all duplicates).\n",
      "Loaded 48 document(s) from documents/natural-product-synthesis-using-multicomponent-reaction-strategies.pdf.\n",
      "No new chunks/pages to add from documents/natural-product-synthesis-using-multicomponent-reaction-strategies.pdf (all duplicates).\n",
      "Loaded 19 document(s) from documents/Angew Chem Int Ed - 2009 - Kumar - Synthesis of Natural Product Inspired Compound Collections.pdf.\n",
      "No new chunks/pages to add from documents/Angew Chem Int Ed - 2009 - Kumar - Synthesis of Natural Product Inspired Compound Collections.pdf (all duplicates).\n",
      "Loaded 15 document(s) from documents/c3np70090a.pdf.\n",
      "No new chunks/pages to add from documents/c3np70090a.pdf (all duplicates).\n",
      "Loaded 24 document(s) from documents/Recent progress in the total synthesis of pyrrolecontaining natural products.pdf.\n",
      "No new chunks/pages to add from documents/Recent progress in the total synthesis of pyrrolecontaining natural products.pdf (all duplicates).\n",
      "Loaded 19 document(s) from documents/c5np00046g.pdf.\n",
      "No new chunks/pages to add from documents/c5np00046g.pdf (all duplicates).\n",
      "Loaded 12 document(s) from documents/b901245c.pdf.\n",
      "No new chunks/pages to add from documents/b901245c.pdf (all duplicates).\n",
      "Loaded 34 document(s) from documents/semipinacol-rearrangement-in-natural-product-synthesis.pdf.\n",
      "No new chunks/pages to add from documents/semipinacol-rearrangement-in-natural-product-synthesis.pdf (all duplicates).\n",
      "Loaded 43 document(s) from documents/c8cs00716k.pdf.\n",
      "No new chunks/pages to add from documents/c8cs00716k.pdf (all duplicates).\n",
      "Loaded 39 document(s) from documents/Angew Chem Int Ed - 2016 - Chung - Stereoselective Halogenation in Natural Product Synthesis.pdf.\n",
      "No new chunks/pages to add from documents/Angew Chem Int Ed - 2016 - Chung - Stereoselective Halogenation in Natural Product Synthesis.pdf (all duplicates).\n",
      "Loaded 50 document(s) from documents/radical-reactions-in-natural-product-synthesis.pdf.\n",
      "No new chunks/pages to add from documents/radical-reactions-in-natural-product-synthesis.pdf (all duplicates).\n",
      "Loaded 19 document(s) from documents/Liebigs Annalen - June 23  1997 - Nicolaou - The Wittig and Related Reactions in Natural Product Synthesis.pdf.\n",
      "No new chunks/pages to add from documents/Liebigs Annalen - June 23  1997 - Nicolaou - The Wittig and Related Reactions in Natural Product Synthesis.pdf (all duplicates).\n",
      "Loaded 29 document(s) from documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf.\n",
      "No new chunks/pages to add from documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf (all duplicates).\n",
      "Loaded 11 document(s) from documents/c3qo00086a.pdf.\n",
      "No new chunks/pages to add from documents/c3qo00086a.pdf (all duplicates).\n",
      "Loaded 16 document(s) from documents/c8cs00379c.pdf.\n",
      "No new chunks/pages to add from documents/c8cs00379c.pdf (all duplicates).\n",
      "Loaded 11 document(s) from documents/b816703f.pdf.\n",
      "No new chunks/pages to add from documents/b816703f.pdf (all duplicates).\n",
      "Done. Added: 0, skipped as duplicates: 548.\n"
     ]
    }
   ],
   "source": [
    "# Re-run to test it's duplicate spotting capabilities\n",
    "main_documents_directory = \"documents\"\n",
    "file_paths = scan_directory(main_documents_directory)\n",
    "# loaded_vstore is a (store, docs) tuple returned by load_docstore_from_dir()\n",
    "vstore = path_upload_document_to_vectorstore(file_paths, loaded_vstore, index_dir=\"vectorstore\", dedup_mode=\"content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38cfe7",
   "metadata": {},
   "source": [
    "<h4>Querying the docstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb86301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docstore_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed30b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FAISS store from 'vectorstore' with 549 document(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 2347.05it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-small-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Is the diels-alder reaction used in natural product synthesis?\n",
      "Top 5 results:\n",
      "\n",
      "================================================================================\n",
      "Result 1\n",
      "Source: documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf\n",
      "Page: 0\n",
      "Hash: 33cc72e8d46b5c83716776c0d89f2f0b447fc02b683d379d5451a1b301a3f811\n",
      "--------------------------------------------------------------------------------\n",
      "Recent Advances in Natural Product Synthesis by Using Intramolecular\n",
      "Diels−Alder Reactions†\n",
      "Ken-ichi Takao, Ryosuke Munakata, and Kin-ichi Tadano*\n",
      "Department of Applied Chemistry, Keio University, Hiyoshi, Kohoku-ku, Yokohama 223-8522, Japan\n",
      "Received March 1, 2005\n",
      "Contents\n",
      "1. Introduction 4779\n",
      "2. Terpenoids 4779\n",
      "2.1. Sesquiterpenoids 4779\n",
      "2.2. Diterpenoids 4782\n",
      "2.3. Sesterterpenoids 4786\n",
      "2.4. Steroids 4787\n",
      "3. Alkaloids 4789\n",
      "3.1. Amaryllidaceae Alkaloids 4789\n",
      "3.2.\n",
      "Stemona Alkaloids 4790\n",
      "3.3. Tropolone Alkaloids 4791\n",
      "3.4. Quinolizidine Alkaloids 4792\n",
      "3.5. Indole Alkaloids 4793\n",
      "3.6. Other Alkaloids 4794\n",
      "4. Polyketides 4796\n",
      "4.1. Chlorothricolide and Tetronolide 4796\n",
      "4.2. Phomoidrides 4797\n",
      "4.3. FR182877 4799\n",
      "4.4. Cochleamycin A and Macquarimicins 4800\n",
      "4.5. Spinosyn A 4801\n",
      "4.6. Tubelactomicin A \n",
      "\n",
      "================================================================================\n",
      "Result 2\n",
      "Source: documents/b816703f.pdf\n",
      "Page: 1\n",
      "Hash: aade7621f22ecc1ce2cf0d93e3167c4adb690cced37d21f9781f9ff365aca902\n",
      "--------------------------------------------------------------------------------\n",
      "Recent applications of intramolecular Diels–Alder reactions to natural\n",
      "product synthesis w\n",
      "Martin Juhl* a and David Tanner* b\n",
      "Received 26th March 2009\n",
      "First published as an Advance Article on the web 29th July 2009\n",
      "DOI: 10.1039/b816703f\n",
      "This tutorial review presents some recent examples of intramolecular Diels–Alder (IMDA)\n",
      "reactions as key complexity-generating steps in the total synthesis of structurally intricate natural\n",
      "products. The opportunities aﬀorded by transannular (TADA) versions of the IMDA reaction in\n",
      "complex molecule assembly are also highlighted. The review is aimed at a wide audience, ranging\n",
      "from advanced undergraduates to seasoned practitioners of total synthesis; since this is an\n",
      "educational overview, only selected highlights from the period 2000–2009 are presented, along\n",
      "\n",
      "================================================================================\n",
      "Result 3\n",
      "Source: documents/recent-advances-in-natural-product-synthesis-by-using-intramolecular-diels-alder-reactions.pdf\n",
      "Page: 26\n",
      "Hash: 5103777010b8d51dde9fabb2b941eb7c1de31d042305daba9b32249a2551abef\n",
      "--------------------------------------------------------------------------------\n",
      "on structurally complex natural products, that is,\n",
      "terpenoids, alkaloids, and polyketide-derived natural\n",
      "products. Although many of the cited natural product\n",
      "syntheses have been the focus of activity for several\n",
      "research groups and a variety of the synthetic ap-\n",
      "proaches have also appeared in the literature, we\n",
      "have introduced in this review completed total syn-\n",
      "thesis alone. Most of the total syntheses cited in this\n",
      "review are milestones of current natural product\n",
      "synthesis. Furthermore, some total syntheses are\n",
      "considered to be mimics to the biogenetic or biosyn-\n",
      "thetic pathway proposed for the target natural prod-\n",
      "uct. The synthetic approaches, guided by the biosyn-\n",
      "thetic consideration for the target natural product,\n",
      "will enhance the importance and effectiveness of\n",
      "IMDA reactions. We c\n",
      "\n",
      "================================================================================\n",
      "Result 4\n",
      "Source: documents/c5np00046g.pdf\n",
      "Page: 2\n",
      "Hash: b5e6c560680a62e4b2c3c4aaf03c54b9f08607d52fa55d2c663c9e0d7cc073f1\n",
      "--------------------------------------------------------------------------------\n",
      "products and bioactive compounds. Consequently, a number of\n",
      "methods have been developed to directly synthesize vicinal all-\n",
      "carbon quaternary centers, including pericyclic, alkylation,\n",
      "photochemical, transition metal-catalyzed, radical, and cyclo-\n",
      "propanation reactions.\n",
      "3\n",
      "Despite the remarkable advances that have been made in the\n",
      "formation of all-carbon quaternary stereocenters in a stereo-\n",
      "selective fashion,\n",
      "4 the direct stereocontrolled construction of\n",
      "vicinal all-carbon quaternary stereocenters remains a consid-\n",
      "erable challenge in contemporary organic synthesis. Further\n",
      "investigations into the development of e ﬃ cient methods to\n",
      "directly and selectively generate such stereochemical arrays\n",
      "should prove valuable.\n",
      "5\n",
      "In 2004, Overman and Peterson presented a perspective on\n",
      "the direct asymm\n",
      "\n",
      "================================================================================\n",
      "Result 5\n",
      "Source: documents/b816703f.pdf\n",
      "Page: 10\n",
      "Hash: 632d5c2e6a8267e6de8033401015ae7a7988cbdc2d83a083f2a64ac88195f4b8\n",
      "--------------------------------------------------------------------------------\n",
      "exquisite cycloaddition process provide rich opportunities for\n",
      "the rapid and selective generation of molecular complexity.\n",
      "Notes and references\n",
      "1( a) O. Diels and K. Alder, Justus Liebigs Ann. Chem., 1928, 460, 98;\n",
      "(b) for a fascinating account of the discovery of the DA reaction\n",
      "and its subsequent impact on organic chemistry, see: J. A. Berson,\n",
      "Chemical Creativity , Wiley-VCH, Weinheim, 1999, ch. 2.\n",
      "2 For a recent review on the Diels–Alder reaction see:\n",
      "T. J. Brocksom, J. Nakamura, M. L. Ferreira and U. Brocksom,\n",
      "J. Braz. Chem. Soc. , 2001, 12, 597.\n",
      "3 K. Takao, R. Munakata and K. Tadano, Chem. Rev. , 2005, 105,\n",
      "4779.\n",
      "4 For recent review of transannular Diels–Alder reactions, see:\n",
      "E. Marsault, A. Toro ´, P. Nowak and P. Deslongchamps,\n",
      "Tetrahedron, 2001, 57, 4243.\n",
      "5 For a recent review of a\n"
     ]
    }
   ],
   "source": [
    "# Load your store (must match the embedding model used to build it)\n",
    "# Loading the store:\n",
    "store,document_list = load_docstore_from_dir()\n",
    "\n",
    "query = \"Is the diels-alder reaction used in natural product synthesis?\"\n",
    "k = 5\n",
    "\n",
    "# Retrieve top-k chunks\n",
    "docs = store.similarity_search(query, k=k)\n",
    "\n",
    "print(f\"Query: {query}\\nTop {k} results:\")\n",
    "for i, d in enumerate(docs, start=1):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Result {i}\")\n",
    "    print(\"Source:\", d.metadata.get(\"source\"))\n",
    "    print(\"Page:\", d.metadata.get(\"page\"))\n",
    "    print(\"Hash:\", d.metadata.get(\"content_hash\"))\n",
    "    print(\"-\"*80)\n",
    "    print(d.page_content[:800])\n",
    "\n",
    "# Asked a question about the Diels-Alder reaction. It returned the document related to that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes. The Diels‑Alder reaction (both intermolecular and intramolecular versions) is widely employed as a key step for constructing the complex carbocyclic frameworks of natural products. The cited reviews describe numerous total syntheses of terpenoids, alkaloids, polyketides and other natural products that rely on Diels‑Alder cycloadditions to generate multiple stereogenic centers in a single operation.\n"
     ]
    }
   ],
   "source": [
    "# Testing with an LLM:\n",
    "\n",
    "# Load the API groq API key:\n",
    "from pathlib import Path\n",
    "# Bespoke API key loader functions:\n",
    "from load_keys import *\n",
    "import os\n",
    "\n",
    "p = Path(\"keys/groq.json\")\n",
    "groq_api_key = load_groq_key(p)\n",
    "os.environ['GROQ_API_KEY'] = groq_api_key\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.2,\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    ")\n",
    "\n",
    "def ask_FAISS_with_LLM(store, question: str, k: int = 6):\n",
    "    docs = store.similarity_search(question, k=k)\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        [f\"[{i+1}] Source={d.metadata.get('source','')} Page={d.metadata.get('page', '')}\\n{d.page_content}\"\n",
    "         for i, d in enumerate(docs)]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"Use ONLY the context to answer the question.\n",
    "    If the answer is not in the context, say \"I don't know based on the provided documents.\"\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    resp = llm.invoke(prompt)\n",
    "    return resp.content, docs\n",
    "\n",
    "question = \"Is the diels-alder reaction used in natural product synthesis?\"\n",
    "answer, retrieved = ask_FAISS_with_LLM(store, question, k=5)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a46fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Several transformations are repeatedly highlighted as especially useful in the synthesis of natural products:\n",
      "\n",
      "* **Enantioselective carbonyl allylation** – used on solid‑phase resin to give high‑yielding, highly enantioenriched lactone intermediates (see the solid‑phase allylation of an immobilised aldehyde with B‑allyl(diisopinocamphenyl)‑borane)【1†L14-L22】.  \n",
      "* **Baeyer–Villiger oxidation** – a classic oxygen‑insertion reaction that converts cyclic ketones into lactones and is cited as a typical “molecular‑editing” step【4†L23-L26】.  \n",
      "* **Ciamician–Dennstedt rearrangement** – a carbon‑insertion reaction that transforms pyrroles into 3‑chloropyridines, also mentioned as a molecular‑editing transformation【4†L27-L30】.  \n",
      "* **Sonogashira Pd/Cu‑catalysed coupling** – employed to forge sp‑sp² C–C bonds in convergent syntheses of enynes and enediynes, e.g. in the total syntheses of calicheamicin γ₁ and dynemicin A【3†L9-L18】【3†L22-L27】.  \n",
      "* **Diels–Alder reactions (including trans‑annular Diels–Alder)** – used after a Sonogashira coupling to construct the core skeleton of complex natural products such as dynemicin A【3†L22-L27】.  \n",
      "* **Multicomponent reactions (MCRs)** – Passerini, Ugi and other three‑component sequences are highlighted for rapidly assembling highly functionalised motifs and for building analogues such as dysibetaine and dehydroaltenuene B【5†L9-L16】【5†L21-L27】.  \n",
      "* **Anion‑relay chemistry (ARC)** – applied to stitch together fragments for the eastern hemisphere of (‑)-2‑epi‑peloruside A【5†L23-L27】.  \n",
      "\n",
      "These reactions (C–C bond‑forming couplings, carbonyl allylation, oxidative insertions, rearrangements, cycloadditions and multicomponent condensations) are among the most popular and widely used transformations in natural‑product synthesis.\n"
     ]
    }
   ],
   "source": [
    "# Seems to work with an LLM\n",
    "\n",
    "# Let's ask another question:\n",
    "question = \"What are some popular transformations used in natural product synthesis?\"\n",
    "answer, retrieved = ask_FAISS_with_LLM(store, question, k=5)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663b669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
